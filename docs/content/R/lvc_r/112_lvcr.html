<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-01-13">
<meta name="description" content="Doing a mixed-effects logistic regression analysis suitable for comparing to a Goldvarb analysis. Part 2: Sum Contrast Coding">

<title>LingMethodsHub - Mixed-Efects Logistic Regression Analysis: Part 2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../content/R/lvc_r/114_lvcr.html" rel="next">
<link href="../../../content/R/lvc_r/110_lvcr.html" rel="prev">
<script src="../../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ES98D09K0F"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-ES98D09K0F', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"express",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean",
  "openSidebar": false,
  "showHighlights": "never"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="LingMethodsHub - Mixed-Efects Logistic Regression Analysis: Part 2">
<meta property="og:description" content="Doing a mixed-effects logistic regression analysis suitable for comparing to a *Goldvarb* analysis. Part 2: Sum Contrast Coding">
<meta property="og:site-name" content="LingMethodsHub">
<meta name="twitter:title" content="LingMethodsHub - Mixed-Efects Logistic Regression Analysis: Part 2">
<meta name="twitter:description" content="Doing a mixed-effects logistic regression analysis suitable for comparing to a *Goldvarb* analysis. Part 2: Sum Contrast Coding">
<meta name="twitter:image" content="https://lingmethodshub.github.io/assets/logo.png">
<meta name="twitter:image-height" content="424">
<meta name="twitter:image-width" content="653">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="Mixed-Efects Logistic Regression Analysis: Part 2">
<meta name="citation_author" content="Matt Hunt Gardner">
<meta name="citation_publication_date" content="2023-01-13">
<meta name="citation_cover_date" content="2023-01-13">
<meta name="citation_year" content="2023">
<meta name="citation_online_date" content="2023-01-13">
<meta name="citation_fulltext_html_url" content="https://lingmethodshub.github.io/112_lvcr.html">
<meta name="citation_doi" content="10.5281/zenodo.7160718">
<meta name="citation_volume" content="Doing LVC with R">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Linguistics Methods Hub">
<meta name="citation_series_title" content="Linguistics Methods Hub">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">LingMethodsHub</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../../index.html" aria-current="page">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/index.html">
 <span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/contributing/index.html">
 <span class="menu-text">Contributing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../people/index.html">
 <span class="menu-text">People</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/LingMethodsHub/LingMethodsHub.github.io"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-reader-toggle nav-link" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Mixed-Efects Logistic Regression Analysis: Part 2</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../../assets/logo.svg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/index.html" class="sidebar-item-text sidebar-link">Tutorials</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../content/R/index.html" class="sidebar-item-text sidebar-link">R</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../content/R/lvc_r/index.html" class="sidebar-item-text sidebar-link">Doing LVC with R</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/010_lvcr.html" class="sidebar-item-text sidebar-link">Getting Started</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/020_lvcr.html" class="sidebar-item-text sidebar-link">Getting Your Data Into <em>R</em></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/030_lvcr.html" class="sidebar-item-text sidebar-link">Getting to Know Your Data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/040_lvcr.html" class="sidebar-item-text sidebar-link">Modifying Data</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/050_lvcr.html" class="sidebar-item-text sidebar-link">Doing it all again, but <code>tidy</code></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/060_lvcr.html" class="sidebar-item-text sidebar-link">Crosstabs: Counts, Proportions, and More</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/070_lvcr.html" class="sidebar-item-text sidebar-link">Proportions for <code>ggplot2</code></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/080_lvcr.html" class="sidebar-item-text sidebar-link">Conditional Inference Trees</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/090_lvcr.html" class="sidebar-item-text sidebar-link">Random Forests: The Basics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/110_lvcr.html" class="sidebar-item-text sidebar-link">Mixed-Efects Logistic Regression Analysis: Part 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/112_lvcr.html" class="sidebar-item-text sidebar-link active">Mixed-Efects Logistic Regression Analysis: Part 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/114_lvcr.html" class="sidebar-item-text sidebar-link">Mixed-Efects Logistic Regression Analysis: Part 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/lvc_r/116_lvcr.html" class="sidebar-item-text sidebar-link">Mixed-Efects Logistic Regression Analysisː Part 4</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/vowel-plots-tutorial/index.html" class="sidebar-item-text sidebar-link">Vowel Plots with <code>ggplot2</code></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/tidy-norm/index.html" class="sidebar-item-text sidebar-link">How to normalize your vowels using the tidyverse</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/R/animated_vowel_plots_tutorial/index.html" class="sidebar-item-text sidebar-link">Visualising Vowel Space Change with GAMMs</a>
  </div>
</li>
          <li class="px-0"><hr class="sidebar-divider hi "></li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../content/python/index.html" class="sidebar-item-text sidebar-link">Python</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/python/vowel-plotting-py/index.html" class="sidebar-item-text sidebar-link">Vowel plotting in Python</a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Praat</span>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../content/tools/index.html" class="sidebar-item-text sidebar-link">Tools</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/tools/mfa/mfa-tutorial/index.html" class="sidebar-item-text sidebar-link">Montreal Forced Aligner</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/tools/autovot/autovot-tutorial/index.html" class="sidebar-item-text sidebar-link">AutoVOT</a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../content/cli/index.html" class="sidebar-item-text sidebar-link">Command Line Interfaces</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/cli/bash-shell-basics/index.html" class="sidebar-item-text sidebar-link">Bash Shell Basics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/cli/keyboarding/index.html" class="sidebar-item-text sidebar-link">Keyboarding</a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../content/windows/index.html" class="sidebar-item-text sidebar-link">Windows</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../content/windows/wsl/index.html" class="sidebar-item-text sidebar-link">Windows Subsystem for Linux</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../content/windows/wsl/00_installing_wsl.html" class="sidebar-item-text sidebar-link">Installation</a>
  </div>
</li>
      </ul>
  </li>
          <li class="px-0"><hr class="sidebar-divider hi "></li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sum-contrasts-vs.-mean" id="toc-sum-contrasts-vs.-mean" class="nav-link active" data-scroll-target="#sum-contrasts-vs.-mean">Sum Contrasts (vs.&nbsp;mean)</a>
  <ul class="collapse">
  <li><a href="#building-your-model" id="toc-building-your-model" class="nav-link" data-scroll-target="#building-your-model">Building Your Model</a></li>
  <li><a href="#interpreting-your-model-getting-constraint-hierarchy" id="toc-interpreting-your-model-getting-constraint-hierarchy" class="nav-link" data-scroll-target="#interpreting-your-model-getting-constraint-hierarchy">Interpreting Your Model, Getting Constraint Hierarchy</a>
  <ul class="collapse">
  <li><a href="#sec-randomeffects" id="toc-sec-randomeffects" class="nav-link" data-scroll-target="#sec-randomeffects">Random Effects</a></li>
  <li><a href="#fixed-effects" id="toc-fixed-effects" class="nav-link" data-scroll-target="#fixed-effects">Fixed Effects</a></li>
  </ul></li>
  <li><a href="#determining-significance-and-magnitude-of-effect" id="toc-determining-significance-and-magnitude-of-effect" class="nav-link" data-scroll-target="#determining-significance-and-magnitude-of-effect">Determining Significance and Magnitude of Effect</a></li>
  <li><a href="#creating-a-manuscript-ready-table" id="toc-creating-a-manuscript-ready-table" class="nav-link" data-scroll-target="#creating-a-manuscript-ready-table">Creating a Manuscript-ready Table</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block">Mixed-Efects Logistic Regression Analysis: Part 2</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>

<div>
  <div class="description">
    Doing a mixed-effects logistic regression analysis suitable for comparing to a <em>Goldvarb</em> analysis. Part 2: Sum Contrast Coding
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    Matt Hunt Gardner <a href="https://orcid.org/0000-0002-1878-4232" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Oxford
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 13, 2023</p>
    </div>
  </div>
  
    
    <div>
    <div class="quarto-title-meta-heading">Doi</div>
    <div class="quarto-title-meta-contents">
      <p class="doi">
        <a href="https://doi.org/10.5281/zenodo.7160718">10.5281/zenodo.7160718</a>
      </p>
    </div>
  </div>
  </div>
  

</header>

<section id="sum-contrasts-vs.-mean" class="level1">
<h1>Sum Contrasts (vs.&nbsp;mean)</h1>
<p>Before you proceed with this section, please make sure that you have your data loaded and modified based on the code <a href="../../../content/R/lvc_r/050_lvcr.html">here</a> and that <code>Dep.Var</code> is <a href="../../../content/R/lvc_r/110_lvcr.html">re-coded such that <code>Deletion</code> is the second factor</a>. Next, you set the global <em>R</em> options to employ sum contrast coding. Now you are ready to create a mixed-effects logistic regression model that is comparable to the model produced by <em>Goldvarb</em>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum Coding (vs. mean)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">"contr.sum"</span>, <span class="st">"contr.poly"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="building-your-model" class="level2">
<h2 class="anchored" data-anchor-id="building-your-model">Building Your Model</h2>
<p>The next step is creating the mixed-effects model. The following code tests the fixed effects of preceding phonological context (<code>Before</code>), following phonological context (<code>After.New</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>), morphological status (<code>Morph.Type</code>), lexical stress of the syllable (<code>Stress</code>), underlying phoneme (<code>Phoneme</code>), speaker age (<code>Centre.Age</code>), speaker sex (<code>Sex</code>) and speaker education level (<code>Education</code><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>), on the deletion of (t ,d) in the data set. It also takes into account the potential random effect of speaker (<code>Speaker</code><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>). The function for creating this model, <code>glmer()</code> (for Generalized Linear Mixed Effects model with Random effects, what I call the “glimmer” [glɪmɚ] function) is part of the <code>lme4</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generalized linear mixed effects model with the fixed main effects of Before,</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># After.New, Morph.Type, Stress, Phoneme, Centre.Age, Sex and Education, and</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># the random effect of Speaker</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>td.glmer <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> Before <span class="sc">+</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    Center.Age <span class="sc">+</span> Sex <span class="sc">+</span> Education <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As with the <code>ctree()</code> function, you construct your <code>gmler()</code> model by first specifying the dependent variable, here <code>Dep.Var</code>, then using <code>~</code> to indicate that everything to the right is a potential predictor of your dependent variable (e.g., the variable on the left varies as a function of the variables on the right). The predictors are separated by a <code>+</code>. You specify that <code>Speaker</code> is a random effect by enclosing it in <code>(1| )</code>. Here the <code>1</code> simply indicates the model’s intercept. You are essentially telling <em>R</em> to assume a different intercept (i.e., baseline likelihood of <code>Deletion</code>) for each level of <code>Speaker</code>. This effectively resolves the non-independence that stems from having multiple tokens by the same speaker. If you wanted to include both speaker and word as random effects, assuming you had columns called <code>Speaker</code> and <code>Word</code>, you could specify <code>+ (1|Speaker) + (1|Word)</code> in your function. If you do not want any random effects in your model, you cannot use <code>glmer()</code>. Instead, you must use <code>glme()</code>.</p>
<p>After specifying your predictors, you indicate that <code>family = "binomial"</code> because you are looking at the binary choice between <code>Deletion</code> and <code>Realization</code>. The specification <code>control = glmerControl(optCtrl = list(maxfun = 2e4), optimizer = "bobyqa")</code> simply tweaks how many function evaluations the <code>glmer()</code> optimizer will try before giving up and declaring non-convergence with an error message. You don’t need to use these specifications. If you don’t, you may get non-convergence warnings — but even if you do, that isn’t necessarily the end of the world. As long as the reason you’re getting the the non-convergence warnings is NOT because of singletons or knockouts in some cells (as a good sociolinguist I know you’ve weeded all of these out based on your cross-tabs), a model with a non-convergence warning like <code>Model failed to converge with max|grad| = 0.0259806 (tol = 0.001, component 1)</code> will still yield explanatory, albeit sub-optimal, test statistic values.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What causes non-convergence?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>There are several things that will cause the model not to converge (i.e., fail). The first (and most common cause) is that your model is too complex. Complexity arises from having too many potential predictors or too many levels within each predictor. This complexity is more pernicious if your data set is small. Tweaking the <code>glmer()</code> controls can help, but it won’t always overcome extreme complexity. The first step, then, when dealing with non-convergence is thinking (from a theoretical perceptive) how you can simplify your model. Using a <a href="../../../content/R/lvc_r/080_lvcr.html">Conditional Inference Tree</a> or <a href="../../../content/R/lvc_r/090_lvcr.html">Random Forest</a> analyses can help — so can a really thorough exploration of you data using <a href="../../../content/R/lvc_r/060_lvcr.html">cross tabs</a>. Cross-tabs especially can help you find whether you have <strong>singletons</strong> or <strong>knockouts</strong>. These terms are hold-overs from <em>Goldvarb</em> for phenomena in your data that can cause non-convergence, but they can also cause non-convergence in a <code>glmer()</code> model.</p>
<p>The following will cause non-convergence or skewed results in your regression analysis. :</p>
<ol type="1">
<li><strong>singleton</strong> — a single-level predictor variable and/or its one level. In the partition <code>td.young</code> the predictor <code>Age.Group</code> is a singleton because the only value is <code>Young</code>. Solution: don’t include this predictor in your model.</li>
<li><strong>knockout</strong> — when a level of a predictor variable always (100% of tokens) or never (0% tokens) occurs with the application value of the dependent variable. Solution: don’t include this level in your model (but account for it in your description of the data), or re-code in a thoeortetically-motivated way.</li>
</ol>
</div>
</div>
</div>
<p>In the code above you used the <code>&lt;-</code> function to assign your model to the object <code>td.glmer</code>. To see the results of the model, use the <code>summary()</code> function on the model object.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ Before + After.New + Morph.Type + Stress + Phoneme +  
    Center.Age + Sex + Education + (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
  1111.1   1192.4   -539.6   1079.1     1173 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-5.0817 -0.4936 -0.2554  0.4880 15.0593 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.6459   0.8036  
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -0.255788   0.202133  -1.265  0.20571    
Before1     -0.563649   0.202605  -2.782  0.00540 ** 
Before2      0.542851   0.193737   2.802  0.00508 ** 
Before3      0.102101   0.278658   0.366  0.71407    
Before4      0.720732   0.190146   3.790  0.00015 ***
After.New1   1.839172   0.157358  11.688  &lt; 2e-16 ***
After.New2  -1.168199   0.144397  -8.090 5.96e-16 ***
Morph.Type1  0.423432   0.140168   3.021  0.00252 ** 
Morph.Type2 -1.882511   0.213596  -8.813  &lt; 2e-16 ***
Stress1     -0.792893   0.137440  -5.769 7.97e-09 ***
Phoneme1     0.280468   0.127699   2.196  0.02807 *  
Center.Age   0.005787   0.008441   0.686  0.49296    
Sex1        -0.122564   0.150397  -0.815  0.41511    
Education1  -0.178905   0.181832  -0.984  0.32517    
Education2   0.647319   0.275276   2.352  0.01870 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Correlation matrix not shown by default, as p = 15 &gt; 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it</code></pre>
</div>
</div>
</section>
<section id="interpreting-your-model-getting-constraint-hierarchy" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-your-model-getting-constraint-hierarchy">Interpreting Your Model, Getting Constraint Hierarchy</h2>
<p>Now that you have the model, what does it tell you? There are all sorts of details in the <code>summary(td.glmer)</code> output, but we’re first just going to focus on the the first few lines.</p>
<p>The beginning of the output simply tells you that you’ve completed a <code>Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod]</code>. This is just name of the function you’ve just executed.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Wait, I thought we were doing logistic regression?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We are. See <a href="https://psyteachr.github.io/stat-models-v1/generalized-linear-mixed-effects-models.html">here</a>.</p>
<p>The basic idea behind <strong>Generalized Linear Models</strong> (not to be confused with General Linear Models) is to specify a <strong>link function</strong> that transforms the response space into a modelling space where we can perform a linear regression, and to capture the dependence of the variance on the mean through a <strong>variance function</strong>. A <strong>Logistic regression</strong>, then, is simply a linear regression analysis of binary data that has been first converted to the logit scale (thus making it “logistic”) and for which the variance function is the variance of the <strong>binomial</strong> distribution.</p>
<p>The key to understanding why we do this is that linear regression predicts the relationship between continuous, unbounded variables. This means that if we model the likelihood of a binary variable (e.g., <span class="math inline">\(0\)</span> vs.&nbsp;<span class="math inline">\(1\)</span>) using linear regression, the model will predict scenarios where the variable could be lower than <span class="math inline">\(0\)</span> or higher than <span class="math inline">\(1\)</span>. This motivates the conversion of the binary variable onto the logit scale.</p>
<p>Usually we express the probability of the application value occurring as a proportion (number of tokens of the application value/total number of tokens). This proportion is bounded by <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. We can also talk about the odds of the application value occurring, which is the ratio of application vales to non-application values. Odds ratios, like proportions, are also bounded on one end, ranging from <span class="math inline">\(1\)</span> to <span class="math inline">\(+\infty\)</span>. Odds ratios, however, can be converted to the logit scale (making them log odds), which allows us to consider this likelihood of the application value on a continuous scale (log odds range from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(+\infty\)</span>).</p>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Probability, Odds Ratios &amp; Logg Odds
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Probability, odds ratios, and log odds are all the same thing, just expressed in different ways. It’s similar to the idea of scientific notation: the number <span class="math inline">\(1,000\)</span> can be written as <span class="math inline">\(1.0\times 10^3\)</span> or even <span class="math inline">\(10\times 10\times 10\)</span>.</p>
<p><strong>Probability</strong> is the probability that an event happens, i.e., that a token is the application value. For example, there are <span class="math inline">\(1189\)</span> tokens, of which <span class="math inline">\(386\)</span> are <code>Deletion</code>. The proportion of deletion is <span class="math inline">\(386/1189\)</span> or approximately <span class="math inline">\(0.32\)</span>. This means any given token has a <span class="math inline">\(32\%\)</span> chance of being a <code>Deletion</code> token.</p>
<p><strong>Odds</strong> (more technically the odds of success) is defined as probability of success divided by the probability of failure. So the odds of a token being the application value (<span class="math inline">\(32\%\)</span> chance of <code>Deletion</code>) has an accompanying odds of failure (<span class="math inline">\(68\%\)</span> chance of <code>Realization</code>). Odds can be expressed as the ratio between these two, or as an <strong>Odds Ratio</strong>: <span class="math inline">\(0.32/0.68\)</span> or approximately <span class="math inline">\(0.47\)</span></p>
<p><strong>Log odds</strong> is the (natural) <a href="https://www.statisticshowto.com/integrals/integral-natural-log-logarithms/">logarithm</a> of the odds: <span class="math inline">\(log_e(0.47) = -0.75\)</span>. A logarithm is just another way to express an exponent: <span class="math inline">\(log_e(0.47) = -0.75\)</span> is identical to <span class="math inline">\(e^{-0.75} = 0.47\)</span>, where <span class="math inline">\(e\)</span> is <a href="https://en.wikipedia.org/wiki/E_(mathematical_constant)">Euler’s number</a>, which is a mathematical constant used for this purpose (the first few numbers of which are <span class="math inline">\(2.718\)</span>). Converting probabilities or odds ratios to log odds results in symmetry around zero, as shown in the following table <a href="https://books.google.com/books?id=tj1Wn5u9gSMC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false">(Jaccard, 2001)</a>:</p>
<table class="table">
<thead>
<tr class="header">
<th>Probability</th>
<th>Odds Ratio</th>
<th>Log Odds</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(0.100\)</span></td>
<td><span class="math inline">\(0.111\)</span></td>
<td><span class="math inline">\(-2.197\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.200\)</span></td>
<td><span class="math inline">\(0.250\)</span></td>
<td><span class="math inline">\(-1.386\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.300\)</span></td>
<td><span class="math inline">\(0.428\)</span></td>
<td><span class="math inline">\(-0.847\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.400\)</span></td>
<td><span class="math inline">\(0.667\)</span></td>
<td><span class="math inline">\(-0.405\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.500\)</span></td>
<td><span class="math inline">\(1.000\)</span></td>
<td><span class="math inline">\(0.000\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.600\)</span></td>
<td><span class="math inline">\(1.500\)</span></td>
<td><span class="math inline">\(0.406\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.700\)</span></td>
<td><span class="math inline">\(2.333\)</span></td>
<td><span class="math inline">\(0.847\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(0.800\)</span></td>
<td><span class="math inline">\(4.000\)</span></td>
<td><span class="math inline">\(1.386\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(0.900\)</span></td>
<td><span class="math inline">\(9.000\)</span></td>
<td><span class="math inline">\(2.197\)</span></td>
</tr>
</tbody>
</table>
<p>See also <a href="https://www.statisticshowto.com/log-odds/" class="uri">https://www.statisticshowto.com/log-odds/</a>.</p>
</div>
</div>
</div>
<p>The next lines of the <code>summary(td.glmer)</code> output is tells you the variance function <code>Family: binomial</code> and the link function <code>(logit)</code> and the formula used to construct the model <code>Formula: Dep.Var ~ Before + After.New + Morph.Type + Stress + Phoneme + Center.Age + Sex + Education + (1 | Speaker)</code>. Next is the data <code>Data: td</code> and the tweak you’ve made to the controls: <code>Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")</code>. This information is not new to you because it’s exactly what you specified.</p>
<p>You are then given some measures of model fit, including <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion"><code>AIC</code></a>, <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion"><code>BIC</code></a>, <code>logLik</code> (log likelihood), and <code>deviance</code>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> These values measure how well your model predicts the actual values of your data. They are measures of prediction error. This is similar to the log-likelihood reported by <em>Goldvarb</em>. Higher values for these measures indicate a worse fit to the data, lower values indicate a better fit to the data. Following these measures you are given the degrees of freedom of the residuals <code>df.resid</code><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> and then descriptors of the scaled residuals (<code>Min</code>, <code>Max</code>, and <code>Mean</code> values and 1st and 3rd quartiles, <code>1Q</code> and <code>3Q</code>). The scaled residuals are simply a description of the variation that is not predicted by the model, or rather, the difference between the predicted and observed results. In large data sets these residuals should be <a href="https://en.wikipedia.org/wiki/Normal_distribution">normally distributed</a>. These measures/residuals are more important for statisticians aiming to craft a model with the best possible fit to the data. They are also somewhat fuzzy to interpret for logistic regression modelling. For your purposes, where the goal is instead to test hypotheses or confirm trends, the goodness of fit of your model or the extent to which is explains all the data is only relevant insofar as it allows you to select the model built with the independent predictors (which you’ve selected to include in your analysis based of good theoretical linguistic/social reasoning) that best explain the variation. In other words, for you, a good model is not one that best fits the data, but rather that is the most sociolinguistically explanatory — that tells the story of the variation in the best possible way.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Which model is best?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Including all the independent predictors you want to test is called creating a <strong>full model</strong> or <strong>maximal model</strong>. Once you start removing un-informative independent predictors from your model, or pruning it, you are entering the territory of model selection, which is as much an art as it is a science. Some statisticians recommend reporting on the full/maximal model, others (like <a href="https://doi.org/10.48550/arXiv.1506.04967">Bates, Kleigl, Vasishth,and Baayen 2018</a>) argue for reporting the most <strong>parsimonious</strong> or the least complex maximally predictive model. Depending on your goals, you may choose to report one or the other. For example, the maximal model may be useful when comparing the same regression analysis across multiple partitions/data sets.</p>
<p>Comparing measures of model fit can be useful when you have two potential predictors that are non-orthogonal (not independent) like education and employment type. You would not include both education and employment type in the same model because in many communities these two factors are not independent of each other. In Cape Breton, for example, white collar workers have higher education levels than blue collar workers. Including only one in a model is usually fine given that both are proxies for social status anyway. But which one do you choose to include?</p>
<p>One way to choose is to construct two identical models, one with <code>Education</code>, one with <code>Job</code>, and then compare how well each fits the data. If, for example, the model with <code>Education</code> fits the data better, you could argue that education level does a better job of explaining the variation than employment type. You could use this same strategy if you wanted to compare models with different coding schemes for certain parameters (like <code>After</code> and <code>After.New</code>).</p>
<p>Comparing goodness of fit is not as easy as just comparing <code>AIC</code> or <code>BIC</code>, etc. though. Often values of goodness of fit measures that are very similar across models may in fact not be significantly different from one another given the differing number of parameter levels in each model. For example, the AIC of the most parsimonious model above constructed with <code>After</code> instead of <code>After.New</code> is <span class="math inline">\(1049.9\)</span> (<span class="math inline">\(13\)</span> parameters). The <code>AIC</code> of the model constructed with <code>After.New</code> (which you’ll remember groups pre-/h/ contexts with other pre-consonantal contexts in order to compare with past research, see <a href="../../../content/R/lvc_r/040_lvcr.html">Modifying Data</a>) is <span class="math inline">\(1113.8\)</span> (<span class="math inline">\(12\)</span> parameters). This lower <code>AIC</code> with <code>After</code> indicates that this model is a better fit to the data than the model constructed with <code>After.New</code>. This is unsurprising given that /h/ disfavours <code>Deletion</code>, but other consonants do not (see the <a href="../../../content/R/lvc_r/080_lvcr.html">Conditional Inference Tree analysis</a>). The difference between the <code>AIC</code> of the two models (given the difference of 1 parameter between them, i.e., degrees of freedom/df = 1) is statistically significantly greater than zero ( <code>Pr(&gt;Chisq) = 4.645e-16</code> or <span class="math inline">\(4.645\times 10^{-16}\)</span>, i.e., <span class="math inline">\(p&lt;0.05\)</span>,). This can be determined using the function <code>anova(td.glmer1, td.glmer2)</code> where <code>td.glmer1</code> and <code>td.glmer2</code> are the same model, but with one using <code>After</code> and the other using <code>After.New</code>. Note that relevant function is <code>anova()</code>, which is used for comparing models, and not <code>Anova()</code>, which is used for evaluating the significance of fixed effects in a model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>td.glmer1 <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>td.glmer2 <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(td.glmer1, td.glmer2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: td
Models:
td.glmer2: Dep.Var ~ After.New + Morph.Type + Before + Stress + Phoneme + (1 | Speaker)
td.glmer1: Dep.Var ~ After + Morph.Type + Before + Stress + Phoneme + (1 | Speaker)
          npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
td.glmer2   12 1113.8 1174.8 -544.92   1089.8                         
td.glmer1   13 1049.9 1115.9 -511.95   1023.9 65.942  1  4.645e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>You can visualize the model fit using the <a href="https://cran.r-project.org/web/packages/arm/arm.pdf"><code>binnedplot()</code></a> function from the <code>arm</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arm)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">predict</span>(td.glmer1)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">resid</span>(td.glmer1)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">binnedplot</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In logistic regression, as with linear regression, the residuals are just the difference between the actual values and the values predicted by the model. Since the dependent variable is binary, the residuals will be binary too (either <span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span>), so plotting the raw residuals is not really that informative. The binned residuals plot above divides the data into categories (bins) based on their fitted (predicted) values and then plots the average residual versus the average fitted value for each bin. In the plot the grey lines indicate plus and minus <span class="math inline">\(2\)</span> standard-error bounds. We expect about <span class="math inline">\(95\%\)</span> of the binned residuals (black dots) to fall between the two grey lines if the model is actually true. By default, for data sets larger than <span class="math inline">\(100\)</span> tokens, the number of bins is the square root of the total number of tokens. You can play with the number of bins with the option <code>nclass=</code>.</p>
<p>Compare the two binned residual plots (above and below). You can see that for the <code>td.glmer2</code> residual plot there are more black dots outside the grey lines, indicating an inferior fit.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arm)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">predict</span>(td.glmer2)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">resid</span>(td.glmer2)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">binnedplot</span>(x, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can do the same thing, but instead testing the difference between models built using a discrete age predictor: <code>Age.Group</code>, versus a continuous age predictor: <code>Center.Age</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>td.glmer3 <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> Center.Age <span class="sc">+</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>td.glmer4 <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> Age.Group <span class="sc">+</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(td.glmer3, td.glmer4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: td
Models:
td.glmer3: Dep.Var ~ After + Morph.Type + Before + Stress + Phoneme + Center.Age + (1 | Speaker)
td.glmer4: Dep.Var ~ After + Morph.Type + Before + Stress + Phoneme + Age.Group + (1 | Speaker)
          npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)
td.glmer3   14 1051.0 1122.1 -511.48   1023.0                     
td.glmer4   15 1052.9 1129.1 -511.44   1022.9 0.0918  1     0.7619</code></pre>
</div>
</div>
<p>The results of this <code>anova()</code> show that the difference in fit of a model built with <code>Center.Age</code> (<code>AIC</code> <span class="math inline">\(= 1051.0\)</span>) and <code>Age.Group</code> (<code>AIC</code> <span class="math inline">\(= 1052.9\)</span>) is not significant (<code>Pr(&gt;Chisq) = 0.7619</code>, or <span class="math inline">\(p&gt;0.05\)</span>), or rather, the choice between the two is inconsequential to modelling the variation in the data.</p>
<p>In may also be useful to report in your manuscript that a model built with your fixed effects does a better job at predicting the variation than a model built with just the random effects (i.e., a <strong>null model</strong>). To make this comparison you build a model with no fixed effects and compare that using the <code>anova()</code> function to your model with fixed effects.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>td.glmer.null <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(td.glmer1, td.glmer.null)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: td
Models:
td.glmer.null: Dep.Var ~ (1 | Speaker)
td.glmer1: Dep.Var ~ After + Morph.Type + Before + Stress + Phoneme + (1 | Speaker)
              npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
td.glmer.null    2 1455.8 1465.9 -725.88   1451.8                         
td.glmer1       13 1049.9 1115.9 -511.95   1023.9 427.86 11  &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>In a manuscript you would report that the model built with fixed effect predictors and the random effect of <code>Speaker</code> (<code>AIC</code><span class="math inline">\(=1049.9\)</span>) does a significantly better job at predicting the variation in the data than a null model built with just the random effect of <code>Speaker</code> (<code>AIC</code><span class="math inline">\(=1455.8\)</span>; <span class="math inline">\(\chi^2=437.86\)</span>, <span class="math inline">\(\text{df}=11\)</span>, <span class="math inline">\(p&lt;0.001\)</span>).</p>
<p>An additional measure of the success of your model is the <span class="math inline">\(R^2\)</span> value. This value tells you the proportion of the variability of the dependent variable that is explained by the independent predictors collectively. <span class="math inline">\(R^2\)</span> squared is a useful metric for multiple linear regression and as such is often requested by reviewers. But <span class="math inline">\(R^2\)</span> does not have the same meaning for logistic regression (binary dependant variables) as it does for linear regression (continuous dependant variables). Statisticians have come up with a variety of analogues of <span class="math inline">\(R^2\)</span> squared for multiple logistic regression referred to collectively as “pseudo <span class="math inline">\(R^2\)</span>”. Given that there are multiple methods of calculating <span class="math inline">\(R^2\)</span>, and that its use for non-linear models is still debated by statisticians, use and report it with a grain of salt.</p>
<p>The easiest way to calculate a (pseudo-)<em>R^2</em> value using the <a href="https://doi.org/10.1111/j.2041-210x.2012.00261.x">Nakagawa &amp; Schielzeth’s (2012)</a> method is to use the function <code>r.squaredGLMM()</code> from the <code>MuMIn</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"MuMIn"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MuMIn)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">r.squaredGLMM</span>(td.glmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  R2m       R2c
theoretical 0.4293394 0.5229847
delta       0.3626576 0.4417586</code></pre>
</div>
</div>
<p>The <code>r.squaredGLMM()</code> function returns a matrix with two calculations each for <code>R2m</code> and <code>R2c</code>. The first, <code>R2m</code> or the marginal <em>R^2</em> value, represents the variance explained by the fixed effects alone. The function calculates this using two different methods. You can just look at the <code>theoretical</code> calculation. It tells you that <code>0.43</code> or <span class="math inline">\(43\%\)</span> of the variance is explained by the fixed effects. The second set of values, the <code>R2c</code> or the conditional <em>R^2</em> value, represents the variance that is explained by the fixed effects plus the random effects. Here <code>0.52</code> or <span class="math inline">\(53\%\)</span> of the variance is explained by the combination of fixed and random effects.</p>
</div>
</div>
</div>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>You cannot meaningfully compare model fit across different data sets. Identical tokens and an identical dependant variable must be included in the two models being compared. This is equally true for comparing AIC and <span class="math inline">\(R^2\)</span>.</p>
</div>
</div>
<section id="sec-randomeffects" class="level3">
<h3 class="anchored" data-anchor-id="sec-randomeffects">Random Effects</h3>
<p>After the measures of model fit is information about the random effects. In <code>td.glmer</code> there is only one random effect: <code>Speaker</code>. It is listed under <code>Groups</code> because the model groups data by <code>Speaker</code>. The <code>(Intercept)</code> is listed under <code>Name</code> because the model allows for variation of the <code>(Intercept)</code> (i.e., baseline likelihood) by level of <code>Speaker</code>. The likelihood of <code>Deletion</code> for all levels of <code>Speaker</code> considered together is found below under <code>Fixed Effect</code>. It is the <code>Estimate</code> value of <code>(Intercept)</code>, e.g., <code>-0.255733</code> log odds. The <code>Variance</code> and the <code>Std.Dev</code> are two different ways of expressing how much the levels of <code>Speaker</code> vary around this baseline value. The <code>Std.Dev</code> is simply the square root of the <code>Variance</code> (<span class="math inline">\(\sqrt{0.6459} = 0.8036\)</span>. There is no consensus among sociolinguistics as to whether to report the value for <code>Variance</code> or <code>Std.Dev</code>. I prefer <code>Std.Dev</code> because it is the same units as the <code>(Intercept)</code>. In a manuscript you can therefore report that the overall baseline probability of the <code>td.glmer</code> model is <span class="math inline">\(-0.255788\)</span> log odds (<span class="math inline">\(\pm 0.806\)</span> log odds, by speaker).</p>
<p>Since we assume these likelihoods are normally-distributed, <span class="math inline">\(95\%\)</span> of the speakers’ likelihoods will be within two standard deviations around the overall likelihood. We can calculate this using simple addition and subtraction, or we can calculate the range using an idealized normal distribution (using <code>qqnorm()</code>). The results of these two calculations are slightly different as they are derived using somewhat different mathematical operations. For your purposes, just choose one method and stick with it. To make your calculations easier you can assign the overall likelihood and random effects standard deviation to their own variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating the 95% range for a normal distribution on the logit scale</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign overall likelihood and random effect standard deviations to their own</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># variables</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.255788</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>td.rsd <span class="ot">&lt;-</span> <span class="fl">0.8036</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># or</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="ot">&lt;-</span> <span class="fu">fixef</span>(td.glmer)[<span class="dv">1</span>]</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>td.rsd <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">unlist</span>(<span class="fu">VarCorr</span>(td.glmer)))</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate +/- 2 standard deviations using a mathematical formula, lower then</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co"># higher</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> td.rsd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept) 
  -1.863085 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> td.rsd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept) 
   1.351508 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the 95% range (2.5% to 97.5%) using an idealized normal</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># distribution on the logit scale</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">mean =</span> td.intercept, <span class="at">sd =</span> td.rsd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -1.830910  1.319333</code></pre>
</div>
</div>
<p>The results of the calculations are reported in log odds. It may be more interpretable to report these values as probabilities.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Converting betweeen Log Odds and Probabilities (Factor Weights)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><em>Goldvarb</em> reports <strong>factor weights</strong>, which are expressed as probabilities; the <code>glmer()</code> function reports <strong>log odds</strong>.</p>
<p>To convert probabilities to log odds use the logit formula <span class="math inline">\(x=log(\frac{p}{1-p})\)</span>, where <span class="math inline">\(p\)</span> is the probability and <span class="math inline">\(x\)</span> is the log odds value. It is much easier, however, to just use the <code>logit()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert probabilities to log odds</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="fu">logit</span>(<span class="fl">0.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.405</code></pre>
</div>
</div>
<p>To convert log odds to probabilities you can use the inverse logit formula <span class="math inline">\(p=\frac{e^x}{(1+e^x)}\)</span>, or the <code>inv.logit()</code> function from the <code>boot</code> package. (If you’ve still got the <code>car</code> package loaded from earlier you may need to reload the <code>boot</code> package.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert log odds to probabilities</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(boot)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="sc">-</span><span class="fl">0.405</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Based on the second calculations, you can report in a manuscript that the mean baseline probability of <code>Deletion</code> in the data is <span class="math inline">\(44\%\)</span> and that the <span class="math inline">\(95\%\)</span> range for individual speakers’ baseline probabilities is <span class="math inline">\(14\%\)</span> to <span class="math inline">\(79\%\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% range converted to probabilities</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">mean =</span> td.intercept, <span class="at">sd =</span> td.rsd))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.138 0.789</code></pre>
</div>
</div>
<p>To get the baseline likelihood for individual speakers you can extract the random effect values using <code>ranef()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get individual baseline likelihoods by speaker</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(td.glmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$Speaker
       (Intercept)
ARSM91    -0.50258
BEAM91    -0.34013
BOUF65    -0.67444
CARM91    -0.59391
CHIF55    -0.11282
CLAF52     0.20791
CLAM73     0.10943
CONM89     0.25294
DAVM90     0.34813
DELF91    -0.47659
DONF15     0.13907
DONM41     0.04716
DONM53    -0.18729
DONM58    -0.63125
DOUF46     0.56661
ELLF29    -0.15042
ELLF61    -0.58827
EVAF92    -0.22506
FRAM93    -0.67112
GARF16    -0.19906
GARF37    -1.00238
GARF87    -0.18074
GARM42    -0.68499
GARM85    -0.58814
GAVF93     0.72170
GAVM90    -0.15733
GOUM91    -0.08336
GREF22     0.78227
GREM45    -0.37970
HANF83    -0.33334
HANM57     0.86675
HAWM90     1.12063
HOLF49     0.77544
HOLM52     0.08846
HUNF22    -0.46537
INGM84     1.12780
INGM87    -0.26438
JOCF91    -0.47713
JOYF91    -0.64378
KAYF29     0.06456
KAYM29     0.52023
LATF53    -1.14944
LELM91    -0.82195
LEOF66    -0.67818
MARM92     1.42939
MOFM55    -0.10666
MORF91     0.00951
NATF84     1.17572
NEIF49     0.21234
PACM94     0.08947
PEIF57     0.16229
PHAM91    -0.05544
ROBM64     0.27022
ROLF91     0.44736
RUDF73     0.25617
SAMF61     0.82955
SILM90    -0.76980
SMIF58    -0.63704
SMIM61     0.58311
STAM21     0.69893
STEF99    -0.56206
STEM42     0.08117
STEM65    -0.35627
TAMF91     0.69922
VICF91     1.54293
VIKF91     0.56214

with conditional variances for "Speaker" </code></pre>
</div>
</div>
<p>For each individual speaker you add their random effect value to the overall baseline likelihood to get that speaker’s baseline likelihood. The baseline likelihood of <code>Deletion</code> for speaker <code>ARSM91</code> is <span class="math inline">\(32\%\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker[<span class="st">"ARSM91"</span>, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.503</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker[<span class="st">"ARSM91"</span>, ], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.758</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">sum</span>(<span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker[<span class="st">"ARSM91"</span>, ], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.319</code></pre>
</div>
</div>
<p>Below is a series of functions that extracts the coefficient (in log-odds) of the random intercept for each speaker and then adds next to those coefficients the frequency of the application value for each speaker, as well as that speaker’s total number of tokens. Finally it orders the speakers from lowest to highest random effect intercept coefficient. There is also an extra step to specify the order of the <code>Dep.Var</code> factor because the following <code>table()}</code> function specifies the level to extract by number and you want to make sure that is <code>Deletion</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create column of Speakers with intercept coefficient</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>td.ranef <span class="ot">&lt;-</span> <span class="fu">add_rownames</span>(<span class="fu">as.data.frame</span>(<span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker), <span class="st">"Speaker"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: `add_rownames()` was deprecated in dplyr 1.0.0.
ℹ Please use `tibble::rownames_to_column()` instead.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(td.ranef)[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="st">"Intercept"</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Reorder levels of Dep.Var to make application value second</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>td<span class="sc">$</span>Dep.Var <span class="ot">&lt;-</span> <span class="fu">factor</span>(td<span class="sc">$</span>Dep.Var, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Realized"</span>, <span class="st">"Deletion"</span>))</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create column of Frequencies</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>speaker.prop <span class="ot">&lt;-</span> <span class="fu">add_rownames</span>(<span class="fu">as.data.frame</span>(<span class="fu">prop.table</span>(<span class="fu">table</span>(td<span class="sc">$</span>Speaker, td<span class="sc">$</span>Dep.Var),</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>)[, <span class="dv">2</span>]), <span class="st">"Speaker"</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(speaker.prop)[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="st">"Percent"</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create column of token counts</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>speaker.n <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">table</span>(td<span class="sc">$</span>Speaker))</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(speaker.n) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Speaker"</span>, <span class="st">"Total N"</span>)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge column of frequencies and column of token counts with column of</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Speakers</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>td.ranef.speaker <span class="ot">&lt;-</span> <span class="fu">merge</span>(td.ranef, speaker.prop, <span class="at">by =</span> <span class="st">"Speaker"</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>td.ranef.speaker <span class="ot">&lt;-</span> <span class="fu">merge</span>(td.ranef.speaker, speaker.n, <span class="at">by =</span> <span class="st">"Speaker"</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Order data from lowest to highest Intercept, reset/delete row names</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>td.ranef.speaker <span class="ot">&lt;-</span> td.ranef.speaker[<span class="fu">order</span>(td.ranef.speaker<span class="sc">$</span>Intercept, td.ranef.speaker<span class="sc">$</span>Percent),</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(td.ranef.speaker) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Show final table, supress rownames</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(td.ranef.speaker, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Speaker Intercept Percent Total N
  LATF53  -1.14944  0.0625      16
  GARF37  -1.00238  0.1429      28
  LELM91  -0.82195  0.0000      12
  SILM90  -0.76980  0.2222      18
  GARM42  -0.68499  0.2308      13
  LEOF66  -0.67818  0.2083      24
  BOUF65  -0.67444  0.1765      17
  FRAM93  -0.67112  0.1053      19
  JOYF91  -0.64378  0.0556      18
  SMIF58  -0.63704  0.2941      17
  DONM58  -0.63125  0.3529      17
  CARM91  -0.59391  0.1176      17
  ELLF61  -0.58827  0.1200      25
  GARM85  -0.58814  0.3333       9
  STEF99  -0.56206  0.1875      16
  ARSM91  -0.50258  0.1905      21
  JOCF91  -0.47713  0.1176      17
  DELF91  -0.47659  0.1111      18
  HUNF22  -0.46537  0.0625      32
  GREM45  -0.37970  0.3889      18
  STEM65  -0.35627  0.0000       2
  BEAM91  -0.34013  0.1250      16
  HANF83  -0.33334  0.0000       4
  INGM87  -0.26438  0.3000      20
  EVAF92  -0.22506  0.2105      19
  GARF16  -0.19906  0.3125      16
  DONM53  -0.18729  0.3125      16
  GARF87  -0.18074  0.1731      52
  GAVM90  -0.15733  0.3684      19
  ELLF29  -0.15042  0.3571      14
  CHIF55  -0.11282  0.3000      20
  MOFM55  -0.10666  0.2857      14
  GOUM91  -0.08336  0.2222      18
  PHAM91  -0.05544  0.2222      27
  MORF91   0.00951  0.1875      16
  DONM41   0.04716  0.4000       5
  KAYF29   0.06456  0.4667      15
  STEM42   0.08117  0.4667      15
  HOLM52   0.08846  0.5000      16
  PACM94   0.08947  0.2667      15
  CLAM73   0.10943  0.5000       4
  DONF15   0.13907  0.3929      28
  PEIF57   0.16229  0.3529      17
  CLAF52   0.20791  0.3529      17
  NEIF49   0.21234  0.3529      17
  CONM89   0.25294  0.3333       9
  RUDF73   0.25617  0.4118      17
  ROBM64   0.27022  0.4375      16
  DAVM90   0.34813  0.3333       9
  ROLF91   0.44736  0.3214      28
  KAYM29   0.52023  0.6250      16
  VIKF91   0.56214  0.3333      18
  DOUF46   0.56661  0.4706      17
  SMIM61   0.58311  0.6250      16
  STAM21   0.69893  1.0000       2
  TAMF91   0.69922  0.3571      14
  GAVF93   0.72170  0.3889      18
  HOLF49   0.77544  0.4444      18
  GREF22   0.78227  0.5294      17
  SAMF61   0.82955  0.5625      16
  HANM57   0.86675  1.0000       3
  HAWM90   1.12063  0.7222      18
  INGM84   1.12780  0.5088      57
  NATF84   1.17572  0.6875      16
  MARM92   1.42939  0.5660      53
  VICF91   1.54293  0.5882      17</code></pre>
</div>
</div>
<p>If you look at the top (<code>head()</code>) and bottom (<code>tail()</code>) of this new table you can see that speakers <code>LATF53</code> and <code>LELM91</code> are the most likely to produce fully-realized (t, d) (even though, in the case of <code>LATF53</code>, the frequency of <code>Deletion</code> is not the lowest), while <code>VICF91</code> and <code>MARM92</code> are the most likely to delete (t, d). This is because the former have an overall higher baseline likelihood (<code>(Intercept)</code>+ random effect estimate) and the latter have an overall lower baseline likelihood (<code>(Intercept)</code> + random effect estimate). This information could be very useful to your analysis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show first six rows of td.ranef.speaker</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(td.ranef.speaker)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Speaker Intercept Percent Total N
1  LATF53    -1.149  0.0625      16
2  GARF37    -1.002  0.1429      28
3  LELM91    -0.822  0.0000      12
4  SILM90    -0.770  0.2222      18
5  GARM42    -0.685  0.2308      13
6  LEOF66    -0.678  0.2083      24</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show last six rows of td.ranef.speaker</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(td.ranef.speaker)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Speaker Intercept Percent Total N
61  HANM57     0.867   1.000       3
62  HAWM90     1.121   0.722      18
63  INGM84     1.128   0.509      57
64  NATF84     1.176   0.688      16
65  MARM92     1.429   0.566      53
66  VICF91     1.543   0.588      17</code></pre>
</div>
</div>
</section>
<section id="fixed-effects" class="level3">
<h3 class="anchored" data-anchor-id="fixed-effects">Fixed Effects</h3>
<p>Looking back again at <code>summary(td.glmer)</code>, at the end of the details of the random effects you are presented with some useful information: <code>Number of obs: 1189, groups:  Speaker, 66</code>. This tells you the total number of tokens in your data set: <code>1189</code>, and the total number of speakers: <code>66</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ Before + After.New + Morph.Type + Stress + Phoneme +  
    Center.Age + Sex + Education + (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1111     1192     -540     1079     1173 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-5.082 -0.494 -0.255  0.488 15.059 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.646    0.804   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -0.25579    0.20213   -1.27  0.20571    
Before1     -0.56365    0.20261   -2.78  0.00540 ** 
Before2      0.54285    0.19374    2.80  0.00508 ** 
Before3      0.10210    0.27866    0.37  0.71407    
Before4      0.72073    0.19015    3.79  0.00015 ***
After.New1   1.83917    0.15736   11.69  &lt; 2e-16 ***
After.New2  -1.16820    0.14440   -8.09    6e-16 ***
Morph.Type1  0.42343    0.14017    3.02  0.00252 ** 
Morph.Type2 -1.88251    0.21360   -8.81  &lt; 2e-16 ***
Stress1     -0.79289    0.13744   -5.77    8e-09 ***
Phoneme1     0.28047    0.12770    2.20  0.02807 *  
Center.Age   0.00579    0.00844    0.69  0.49296    
Sex1        -0.12256    0.15040   -0.81  0.41511    
Education1  -0.17890    0.18183   -0.98  0.32517    
Education2   0.64732    0.27528    2.35  0.01870 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Correlation matrix not shown by default, as p = 15 &gt; 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it</code></pre>
</div>
</div>
<p>Next you have the analysis of fixed effects. In the leftmost column you have a list of the levels of each parameter minus one. More on that in a moment. For each level there is an estimate value, also called the coefficient. This value, expressed in log odds, is like a factor weight. Unlike factor weights which are centred around <span class="math inline">\(0.5\)</span> and range from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span>, log odds are centred around <span class="math inline">\(0\)</span> and range from <span class="math inline">\(+\infty\)</span> to <span class="math inline">\(-\infty\)</span>. Parameter levels with positive polarity log odds favour the application value relative to that parameter’s baseline likelihood. Parameter levels with negative polarity log odds disfavour the application value relative to that parameter’s baseline likelihood.</p>
<p>The coefficient for the <code>(Intercept)</code>, as described above, is the overall baseline likelihood. It is the likelihood, all things being equal, that any given token will have the application value rather than the non-application value. It is the mean of the baseline likelihoods of all the parameters in the model. It is just like the input value reported in <em>Goldvarb</em>. You can also refer to it as the centred mean. This value is usually reported in your manuscript as a probability. You can use the <code>inv.logit()</code> function to convert it to a probability (see above).</p>
<p>After the <code>(Intercept)</code> is the name of each predictor followed by a number (e.g., <code>Before1</code>). Each number represents a different level of that predictor, but one level is missing. This is an annoying consequence of the <code>lme4</code> package being built for the conventions of other disciplines where sum contrasts are less commonly used. The numbers correspond to the order of factors within the level. You can double-check this order using the function </p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the levels of a column Before</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(td<span class="sc">$</span>Before)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Liquid"          "Nasal"           "Other Fricative" "S"              
[5] "Stop"           </code></pre>
</div>
</div>
<p>The levels will always be in alphabetical order unless you explicitly change them. In your results, <code>Before1</code> is <code>Liquid</code>, <code>Before2</code> is <code>Nasal</code>, <code>Before3</code> is <code>Other Fricative</code>, and <code>Before4</code> is <code>S</code>. The “missing” level is the last level, <code>Stop</code>. Because the log odds for all levels of a parameter are centred around the mean, you can actually calculate the estimate/coefficient for this last level. The sum off all coefficients for a single parameter will equal zero. Therefore the coefficient of the missing level will be 0 minus the sum of all the remaining coefficients for that parameter. So the estimate for <code>Stop</code> is:</p>
<p><span class="math display">\[\begin{equation*}
0= [\text{Before1}x + \text{Before2}x + \text{Before3}x + \text{Before4}x] + \text{Missing Coefficient}\\
\end{equation*}\]</span> Thus… <span class="math display">\[\begin{equation*}
0- [\text{Before1}x + \text{Before2}x + \text{Before3}x + \text{Before4}x] =\text{Missing Coefficient}
\end{equation*}\]</span></p>
<p>We can extract the specific values using the <code>fixef()</code> function and the position of the coefficients in the list.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the coefficients for the fixed effects</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span>(td.glmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)     Before1     Before2     Before3     Before4  After.New1 
   -0.25579    -0.56365     0.54285     0.10210     0.72073     1.83917 
 After.New2 Morph.Type1 Morph.Type2     Stress1    Phoneme1  Center.Age 
   -1.16820     0.42343    -1.88251    -0.79289     0.28047     0.00579 
       Sex1  Education1  Education2 
   -0.12256    -0.17890     0.64732 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subtract the sum of the coefficients from 0 by name</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span> <span class="sc">-</span> <span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="fu">c</span>(<span class="st">"Before1"</span>, <span class="st">"Before2"</span>, <span class="st">"Before3"</span>, <span class="st">"Before4"</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.802</code></pre>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subtract the sum of the coefficients from 0 more easily by position</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span> <span class="sc">-</span> <span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.802</code></pre>
</div>
</div>
<p>Using the <code>inv.logit()</code> function, you can also calculate the probabilities (e.g., centered factor weights) for each of these parameter levels. We can adjust the number of significant digits so that <em>R</em> does your rounding automatically.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set number of significant digits to 2</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Liquid</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before1"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Before1 
   0.36 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Nasal</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before2"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Before2 
   0.63 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Other Fricative</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before3"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Before3 
   0.53 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of S</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before4"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Before4 
   0.67 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Stop</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="dv">0</span> <span class="sc">-</span> <span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.31</code></pre>
</div>
</div>
<p>Based on this calculation you now know that the constraint hierarchy based on factor weight-like probabilities for preceding segment is <code>S</code> (<span class="math inline">\(0.67\)</span>) &gt; <code>Nasal</code> (<span class="math inline">\(0.63\)</span>) &gt;<code>Other Fricative</code> (<span class="math inline">\(0.53\)</span>) &gt; <code>Liquid</code> (<span class="math inline">\(0.36\)</span>) &gt; <code>Stop</code> (<span class="math inline">\(0.31\)</span>). An easier way to get these values is with the combination of <code>plogis()</code>, which converts log odds to probabilities like <code>inv.logit()</code>, and <code>fct_rev()</code>, which reverses the order of factors. Re-creating <code>td.glmer</code> with all parameter levels being reversed means the final/“missing” levels in <code>td.glmer</code> are now the first levels. So, for <code>td.glmer.reversed</code> we only look at <code>fct_rev(Before)1</code>, <code>fct_rev(Morph.Type)1</code>, etc. This is a quick way to get the values for the missing levels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get probabilities for all estimates in td.glmer</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">fixef</span>(td.glmer))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)     Before1     Before2     Before3     Before4  After.New1 
       0.44        0.36        0.63        0.53        0.67        0.86 
 After.New2 Morph.Type1 Morph.Type2     Stress1    Phoneme1  Center.Age 
       0.24        0.60        0.13        0.31        0.57        0.50 
       Sex1  Education1  Education2 
       0.47        0.46        0.66 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-create td.glmer with all parameters with reversed factor orders</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>td.glmer.reversed <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> <span class="fu">fct_rev</span>(Before) <span class="sc">+</span> <span class="fu">fct_rev</span>(After.New) <span class="sc">+</span> <span class="fu">fct_rev</span>(Morph.Type) <span class="sc">+</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fct_rev</span>(Stress) <span class="sc">+</span> <span class="fu">fct_rev</span>(Phoneme) <span class="sc">+</span> Center.Age <span class="sc">+</span> <span class="fu">fct_rev</span>(Sex) <span class="sc">+</span> Education <span class="sc">+</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get probabilities for all estimates in td.glmer.reversed. Just looking at the</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="co"># first value (which corresponds to the final/missing value in td.glmer)</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">fixef</span>(td.glmer.reversed))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         (Intercept)     fct_rev(Before)1     fct_rev(Before)2 
                0.44                 0.31                 0.67 
    fct_rev(Before)3     fct_rev(Before)4  fct_rev(After.New)1 
                0.53                 0.63                 0.34 
 fct_rev(After.New)2 fct_rev(Morph.Type)1 fct_rev(Morph.Type)2 
                0.24                 0.81                 0.13 
    fct_rev(Stress)1    fct_rev(Phoneme)1           Center.Age 
                0.69                 0.43                 0.50 
       fct_rev(Sex)1           Education1           Education2 
                0.53                 0.46                 0.66 </code></pre>
</div>
</div>
<p>These values are not the overall probability for each level, but rather centred probablity/factor weights. An estimate of <span class="math inline">\(0\)</span> log odds (<span class="math inline">\(0.50\)</span> probability) indicates the likelihood/probability for tokens of that predictor level is equal to the overall likelihood <code>(Intercept)</code>. To get the actual probability for a given level, you have to add its estimate to the <code>(Intercept)</code>. The overall likelihood for <code>Female</code> (e.g.,<code>Sex1</code>) tokens is thus <span class="math inline">\(-0.38\)</span> log odds or <span class="math inline">\(41\%\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the estimate for Sex1 to the estimate for (Intercept)</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Sex1"</span>], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.38</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the sum of the estimates for Sex1 and (Intercept) to probability</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Sex1"</span>], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.41</code></pre>
</div>
</div>
<p>Returning now to the <code>summary(td.glmer)</code>, in the second and third columns of the fixed effects, the standard error and <span class="math inline">\(z\)</span> value are reported. Both are used to calculate the estimate. Whether the difference in likelihood represented by the estimate/coefficient for each level is significantly different from zero (i.e., equal to the overall likelihood <code>(Intercept)</code>) is also calculated using the standard error and is reported in the fourth column. The <code>Pr(&gt;|z|)</code> value is the probability that this difference is equal to zero. The asterisks indicate whether this probability is lower than increasingly smaller thresholds. Generally, in the humanities and social sciences we use <span class="math inline">\(p&gt;0.05\)</span> as our significance threshold,<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> so anything with at least one asterisk is considered significant. For the levels of <code>Before</code>, the coefficients for <code>Liquid</code> (<code>Before1</code>), <code>Nasal</code> (<code>Before1</code>), and <code>S</code> (<code>Before4</code>) are significantly different from zero. In other words, the likelihood of <code>Deletion</code> for these tokens is significantly different from the baseline. This is not the case for <code>Other Fricative</code> (<code>Before3</code>) tokens. For the “missing” level, <code>Stop</code>, you know that the coefficient/estimate is <code>-0.8020349596</code> which is a greater negative number than the estimate for <code>Before1</code>, so you can infer that this difference must also be significant. To verify you can reorder the levels of <code>Before</code> such that <code>Stop</code> is no longer the last factor. You can do this by creating a new column with reordered factors, or you can use the <code>fct_rev()</code> function to do the same inside the <code>glmer()</code> formula.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-order Before in reverse alphabetical order</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>td<span class="sc">$</span>Before.Reorder <span class="ot">&lt;-</span> <span class="fu">factor</span>(td<span class="sc">$</span>Before, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Stop"</span>, <span class="st">"S"</span>, <span class="st">"Other Fricative"</span>,</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Nasal"</span>, <span class="st">"Liquid"</span>))</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-create td.glmer with reordered Before</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>td.glmer.reorder <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> Before.Reorder <span class="sc">+</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Stress <span class="sc">+</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>    Phoneme <span class="sc">+</span> Center.Age <span class="sc">+</span> Sex <span class="sc">+</span> Education <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative method</span></span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>td.glmer.reorder <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> <span class="fu">fct_rev</span>(Before) <span class="sc">+</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Stress <span class="sc">+</span></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>    Phoneme <span class="sc">+</span> Center.Age <span class="sc">+</span> Sex <span class="sc">+</span> Education <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.reorder)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ fct_rev(Before) + After.New + Morph.Type + Stress +  
    Phoneme + Center.Age + Sex + Education + (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1111     1192     -540     1079     1173 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-5.082 -0.494 -0.255  0.488 15.060 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.646    0.804   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
                 Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)      -0.25579    0.20213   -1.27  0.20571    
fct_rev(Before)1 -0.80205    0.18917   -4.24  2.2e-05 ***
fct_rev(Before)2  0.72072    0.19015    3.79  0.00015 ***
fct_rev(Before)3  0.10216    0.27866    0.37  0.71391    
fct_rev(Before)4  0.54284    0.19374    2.80  0.00508 ** 
After.New1        1.83918    0.15736   11.69  &lt; 2e-16 ***
After.New2       -1.16821    0.14440   -8.09  6.0e-16 ***
Morph.Type1       0.42345    0.14017    3.02  0.00252 ** 
Morph.Type2      -1.88255    0.21360   -8.81  &lt; 2e-16 ***
Stress1          -0.79289    0.13744   -5.77  8.0e-09 ***
Phoneme1          0.28047    0.12770    2.20  0.02807 *  
Center.Age        0.00579    0.00844    0.69  0.49294    
Sex1             -0.12256    0.15040   -0.81  0.41511    
Education1       -0.17891    0.18183   -0.98  0.32514    
Education2        0.64733    0.27528    2.35  0.01870 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Correlation matrix not shown by default, as p = 15 &gt; 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it</code></pre>
</div>
</div>
<p>You can see above that the coefficient/estimate for <code>Before.Reorder</code>, which you know is <code>Stop</code>, is <code>-0.80205</code>— nearly identical to what you calculated (the difference is due to rounding). You can see based on the value for <code>Pr(.|z|)</code> that <span class="math inline">\(p=2.2\times 10^{-5]}\)</span>, which is definitely lower than <span class="math inline">\(0.05\)</span>, i.e., significant.</p>
<p>For sum contrast coding, the <code>Pr(&gt;|z|)</code> value for the <code>(Intercept)</code> tells you whether the baseline likelihood is significantly different from <span class="math inline">\(0\)</span> — but remember, <span class="math inline">\(0\)</span> log odds is equivalent to a probability of <span class="math inline">\(50\%\)</span> or a <span class="math inline">\(50/50\)</span> chance of a token being <code>Deletion</code>. For the intercept here, the value is <span class="math inline">\(-0.277\)</span> log odds (or <span class="math inline">\(44\%\)</span> probability), which the model can’t verify as being statistically significantly different from <span class="math inline">\(0\)</span> log odds (<span class="math inline">\(50\%\)</span> probability).</p>
<p>Following the fixed effects there is usually a matrix of correlations. With many predictors or with predictors with many levels this correlation matrix can be very large. If the matrix is too large <em>R</em> will not print it automatically. Don’t worry too much about the correlation matrix right now. We will return to it in <a href="../../../content/R/lvc_r/114_lvcr.html">Part 3</a>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Visualizing the Fixed Effects
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A useful way to visualize the fixed effects is with the function <code>plot_model()</code> from the <code>sjPlot</code> and affiliated packages. You should have <code>ggplot2</code> already installed if you’ve been following along.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install sjPlot and affiliated pacakges</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">c</span>(<span class="st">"sjPlot"</span>, <span class="st">"sjlabelled"</span>, <span class="st">"sjmisc"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required packages</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjlabelled)</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjmisc)</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects</span></span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In the plot the default <em>x</em>-axis is transformed to odds ratios. You’ll remember that odds ratios are mathematically equivalent to both log odds and probabilities. To show either of these in plot, you can use the <code>transform=</code> option, <code>NULL</code> (no transformation) for log odds and <code>"plogis"</code> for probabilities.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with log odds as the x-axis</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="cn">NULL</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with probabilities as the x-axis</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="st">"plogis"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-30-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>You’ll see that for the log odds plot the values are centered around <span class="math inline">\(0\)</span> (no effect), which is equivalent to 1 odds ratio in the odds ratio plot, or <span class="math inline">\(0.50\)</span> probability in the probability plot. The dots represent the estimate of the fixed effects. The lines extending to the right and left of the dots represent the bounds of the standard error. If the standard error does not cross the center line then the effect is statistically significant. The red dots in the log odds and odds ratio plots indicate values below the center line, red values indicate values below the center line. In the probability plot the values are all unfortunately red. As with the output of the sum contrast <code>glmer()</code> model, there is also unfortunately one “missing” value for each predictor.</p>
<p>You can show the estimate values using the option <code>show.values = TRUE</code>. Doing so also adds the significance asterisks (which can be suppressed, if desired, with <code>show.p = FALSE</code>). The values will be plotted directly on top of the points, so use <code>value.offset</code> to adjust the relative positioning. You can also highlight the center line with the <code>vline.color</code> option.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with log odds as the x-axis, estimates and significance</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="co"># showing, and highlighted center line</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="cn">NULL</span>, <span class="at">show.values =</span> <span class="cn">TRUE</span>, <span class="at">value.offset =</span> <span class="fl">0.3</span>, <span class="at">vline.color =</span> <span class="st">"black"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>You can see that all error bars that cross the center line are not significant. You can sort the individual levels of the predictors from most favouring to least favouring using the option <code>sort.est = TRUE</code>. You can change the title using <code>title =</code>. You can also make this graph readable in non-colored manuscripts using <code>color="bw"</code> or <code>color = "gs"</code> and employ some of the themes you encountered <a href="../../../content/R/lvc_r/070_lvcr.html">in previous chapters</a>. Other tweaks to the plot can be found <a href="https://cran.r-project.org/web/packages/sjPlot/vignettes/plot_model_estimates.html">here</a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with log odds as the x-axis, estimates and significance</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co"># showing, highlighted center line, and sorted estimates</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="cn">NULL</span>, <span class="at">show.values =</span> <span class="cn">TRUE</span>, <span class="at">value.offset =</span> <span class="fl">0.3</span>, <span class="at">vline.color =</span> <span class="st">"black"</span>,</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">sort.est =</span> <span class="cn">TRUE</span>, <span class="at">title =</span> <span class="st">"Likelihood of (t,d) deletion"</span>, <span class="at">colors =</span> <span class="st">"gs"</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-32-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>While this type of plot may be less useful when reporting on a sum contrast regression analysis (as there are missing values), it is very useful when reporting on <a href="../../../content/R/lvc_r/116_lvcr.html">treatment contrast regression analyses</a>. You can also plot the random effects per <code>Speaker</code> by using the option <code>type = "rf"</code>. This provides similar information as you extracted from the <code>glmer()</code> model in <a href="#sec-randomeffects">Section&nbsp;1.2.1</a>. To sort this plot by random effect estimate you also need to add <code>grid = FALSE</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot random effects with log odds as the x-axis, estimates and significance</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="co"># showing, highlighted center line, and sorted estimates</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">type =</span> <span class="st">"re"</span>, <span class="at">transform =</span> <span class="cn">NULL</span>, <span class="at">vline.color =</span> <span class="st">"black"</span>, <span class="at">sort.est =</span> <span class="st">"sort.all"</span>,</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">grid =</span> <span class="cn">FALSE</span>, <span class="at">title =</span> <span class="st">"Random effect per Speaker"</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="112_lvcr_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The above plot shows that, based on the standard error, only five speakers have baseline likelihoods of <code>Deletion</code> significantly different from the overall intercept: <code>GARF37</code> and <code>LATF53</code> have a significantly lower baseline likelihood of <code>Deletion</code>, while <code>VICF91</code>, <code>MARM92</code>, <code>NATF84</code>, <code>INGM84</code> and <code>HAWM90</code> have a significantly higher baseline likelihood of deletion.</p>
</div>
</div>
</div>
</section>
</section>
<section id="determining-significance-and-magnitude-of-effect" class="level2">
<h2 class="anchored" data-anchor-id="determining-significance-and-magnitude-of-effect">Determining Significance and Magnitude of Effect</h2>
<p>Let’s return now to the <strong>three lines of evidence</strong>. Does the model tell you which factors groups are significant predictors of the dependent variable? The answer: sort of. It tells you which levels of certain predictors are significantly different from the baseline, but this isn’t the same thing as signalling which predictors, collectively, create the best (e.g., most explanatory) model of the variation — the way <em>Goldvarb</em>’s step-up/step-down model does. In other words, you aren’t provided with the first two lines of evidence. You can figure out the third line of evidence, constraint hierarchy, but this would be the constraint hierarchy in what could conceivably be an overstuffed model. What you need is a tool to determine which factors <strong>should</strong> be in the model — or, rather, which factors actually explain the variation and which factors are erroneous. For this you can use the Wald <span class="math inline">\(\chi^2\)</span> test. The Wald <span class="math inline">\(\chi^2\)</span> test iteratively adds and removes each factor group/predictor, known as a parameter of the model, and compares how well each iteration fits the distribution of the data. If a parameter is found to be significant, it is interpreted as adding explanatory value. If a parameter is not significant, its contribution is superfluous to the understanding of the data and can be set aside. In this way, the Wald <span class="math inline">\(\chi^2\)</span> test is very similar to the step-up/step-up down procedure implemented by <em>Goldvarb</em>. The result of the Wald <span class="math inline">\(\chi^2\)</span> test reveals what combination of original parameters make the most parsimonious model, or rather, a group of original factors that only includes those that contribute significantly to predicting the variation.</p>
<p>The Wald <span class="math inline">\(\chi^2\)</span> test is part of the <code>car</code> package. The function, <code>Anova()</code> is performed on an object, in this case <code>td.glmer</code>, which is the result of a previously-performed logistic regression. Be careful, though! There is another function <code>anova()</code>, which does not perform the Wald <span class="math inline">\(\chi^2\)</span> test and is instead used for comparing different models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Wald Chi-Square test of most parsimonious model</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(td.glmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table (Type II Wald chisquare tests)

Response: Dep.Var
            Chisq Df Pr(&gt;Chisq)    
Before      38.67  4    8.1e-08 ***
After.New  147.85  2    &lt; 2e-16 ***
Morph.Type  77.77  2    &lt; 2e-16 ***
Stress      33.28  1    8.0e-09 ***
Phoneme      4.82  1      0.028 *  
Center.Age   0.47  1      0.493    
Sex          0.66  1      0.415    
Education    5.60  2      0.061 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The results of the Wald <span class="math inline">\(\chi^2\)</span> test gives you the first line of evidence. They show you which factor groups, or parameters, add explanatory value to the model and which don’t. This is functionally equivalent to the selection of significant factors in a step-up/step-down procedure. The results also tell you the relative magnitude of effect of each parameter. The larger the <span class="math inline">\(\chi^2\)</span> statistic (<code>Chisq</code>), the greater magnitude of effect. Using <span class="math inline">\(p&gt;0.05\)</span> as the cut-off you see that <code>Before</code>, <code>After.New</code>, <code>Morph.Type</code>, <code>Stress</code>, and <code>Phoneme</code> all add explanatory value. <code>Centre.Age</code>, <code>Sex</code>, and <code>Education</code> do not (unsurprising given the results of the <a href="../../../content/R/lvc_r/090_lvcr.html">Random Forest</a> analysis). This means that the finding that there is a division between men and women, and among men between those born before and after 1990 (as suggested by the <a href="../../../content/R/lvc_r/080_lvcr.html">Conditional Inference Tree</a> analysis), is in fact not real once you take the linguistic factors, and the random effect of speaker, into account. Put another way, you do not have statistical validation for the observed trend in the summary statistics. In the Wald <span class="math inline">\(\chi^2\)</span> results, <code>After.New</code> has the largest <span class="math inline">\(\chi^2\)</span> value (<span class="math inline">\(147.85\)</span>) indicating it has the largest magnitude of effect on the variation. This is functionally equivalent to saying that its factor weights have the largest range. In descending order you then have <code>Morph.Type</code> (<span class="math inline">\(\chi^2 = 77.77\)</span>), <code>Before</code> (<span class="math inline">\(\chi^2 = 38.67\)</span>), <code>Stress</code> (<span class="math inline">\(\chi^2 = 33.28\)</span>), and <code>Phoneme</code> (<span class="math inline">\(\chi^2 = 4.82\)</span>).</p>
<p>Here is how you might represent these results in a manuscript:</p>
<div id="fig-wald" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/waldtest.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption">Table&nbsp;1: Analysis of deviance, Wald <span class="math inline">\(\chi^2\)</span> test for full model, Deletion of word-final (t, d) in Cape Breton English</figcaption><p></p>
</figure>
</div>
<p>The last line of evidence is the constraint hierarchy, or rather, the order of constraints from most favouring to least favouring. This last line of evidence in <em>Goldvarb</em> requires factor weights. Specifically, it requires the factor weights from the best step-up model and best step-down model — which should match. To re-create the equivalent model you simply create the most parsimonious model identified by the Wald <span class="math inline">\(\chi^2\)</span> test. Here, that is a model constructed with only <code>After.New</code>, <code>Morph.Type</code>, <code>Before</code>, <code>Stress</code>, and <code>Phoneme</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Most Parsimonious Model: Generalized linear mixed effects model with the</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="co"># fixed main effects of Before, After.New, Morph.Type, Stress, Phoneme, and the</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="co"># random effect of Speaker</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>td.glmer.parsimonious <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    Phoneme <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.parsimonious)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ After.New + Morph.Type + Before + Stress + Phoneme +  
    (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1114     1175     -545     1090     1177 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-5.223 -0.488 -0.259  0.495 14.033 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.796    0.892   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -0.277      0.207   -1.34  0.18034    
After.New1     1.840      0.157   11.71  &lt; 2e-16 ***
After.New2    -1.175      0.144   -8.14  4.1e-16 ***
Morph.Type1    0.426      0.140    3.05  0.00230 ** 
Morph.Type2   -1.892      0.213   -8.87  &lt; 2e-16 ***
Before1       -0.575      0.202   -2.84  0.00447 ** 
Before2        0.526      0.193    2.72  0.00659 ** 
Before3        0.117      0.278    0.42  0.67370    
Before4        0.731      0.190    3.85  0.00012 ***
Stress1       -0.799      0.137   -5.81  6.2e-09 ***
Phoneme1       0.287      0.128    2.25  0.02462 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) Aft.N1 Aft.N2 Mrp.T1 Mrp.T2 Befor1 Befor2 Befor3 Befor4
After.New1   0.064                                                        
After.New2  -0.104 -0.430                                                 
Morph.Type1 -0.434  0.203 -0.114                                          
Morph.Type2 -0.051 -0.221  0.178 -0.376                                   
Before1     -0.296 -0.223  0.293  0.052  0.429                            
Before2     -0.164  0.191 -0.094 -0.110  0.247  0.029                     
Before3      0.150  0.018 -0.060  0.319 -0.515 -0.421 -0.477              
Before4      0.250  0.304 -0.431 -0.202  0.051 -0.311 -0.090 -0.274       
Stress1     -0.434 -0.432 -0.064  0.050  0.097  0.056  0.125 -0.094 -0.250
Phoneme1     0.459  0.149 -0.307 -0.137 -0.265 -0.543 -0.263  0.149  0.438
            Strss1
After.New1        
After.New2        
Morph.Type1       
Morph.Type2       
Before1           
Before2           
Before3           
Before4           
Stress1           
Phoneme1    -0.107</code></pre>
</div>
</div>
</section>
<section id="creating-a-manuscript-ready-table" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-manuscript-ready-table">Creating a Manuscript-ready Table</h2>
<p>The estimates or coefficients give us the last line of evidence — and the last piece of statistical information that is generally reported in a standard <em>Goldvarb</em>-style manuscript table. <a href="#fig-gvtable1">Table&nbsp;2</a> is such a table constructed using the information from the <code>td.glmer.parsimonious</code> regression analysis.</p>
<div id="fig-gvtable1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/gvtable.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Table&nbsp;2: Mixed effects logistic regression analysis of the contribution of external and internal factors to the probability of /t, d/ -deletion in Cape Breton English</figcaption><p></p>
</figure>
</div>
<p>The <em>Input</em> is the estimate of the intercept, converted to a probability using the <code>inv.logit()</code> function. You can quickly get these values using <code>plogis(fixef(td.glmer.parsimonious))</code>. The <em>Total N</em>, frequencies and <em>n</em> counts for each factor come from the summary statistics you <a href="../../../content/R/lvc_r/060_lvcr.html">performed earlier</a>. The factor weights for each factor are that factor’s estimates converted to probabilities, again using the <code>inv.logit()</code> or <code>plogis()</code> function. Any mixed-effects model with a random effect should report the random effect. <em>Speaker</em> is listed as a random effect, and the dispersion among speakers is reported. As noted above, there is no consensus around whether to report the <code>Variance</code> or <code>Std.Dev</code> as the measure of this dispersion (remember standard deviation is simply the square root of the variance). Here I’ve reported standard deviation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">fixef</span>(td.glmer.parsimonious))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)  After.New1  After.New2 Morph.Type1 Morph.Type2     Before1 
       0.43        0.86        0.24        0.61        0.13        0.36 
    Before2     Before3     Before4     Stress1    Phoneme1 
       0.63        0.53        0.68        0.31        0.57 </code></pre>
</div>
</div>
<p>The range for each factor group is the difference between the largest factor weight and the lowest factor weight expressed as a whole number. Notice that the ordering of magnitude of effect by the range of probabilities is slightly different from the ordering of magnitude of effect based on the <span class="math inline">\(\chi^2\)</span> coefficient from the Wald <span class="math inline">\(\chi^2\)</span> test and the ordering from the <a href="../../../content/R/lvc_r/090_lvcr.html">Random Forest</a> analysis. For this reason it may be prudent to be very careful when using magnitude of effect/the second line of evidence to compare similarity/difference across data sets. Using multiple means to assess magnitude of effect is warranted, as is being very transparent about the means you use.</p>
<p>Many who create <em>Goldvarb</em>-style tables using data from either <em>Rbrul</em> or <em>R</em>’s <code>glmer()</code> function report both the log odds and factor weights for a given factor (e.g., <a href="https://doi.org/10.1017/S0954394512000026">Drummond 2012</a>, Tables 3-8; <a href="https://doi.org/10.1017/S0954394514000064">Becker 2014</a>, Tables 5-6, etc.). I have not done so in the <a href="#fig-gvtable1">Table&nbsp;2</a> because reporting both is redundant: probability (factor weights), odds-ratios, and likelihood (log odds) are functionally the same, and one can be derived from the other mathematically. Finally, if you wanted to report the factor weights, proportions, and token counts for non-significant factors you could do so (of course, following conventions of the field by enclosing the factor weights in square brackets and not reporting the range) with values taken from the full (not most-parsimonious) model and the summary statistics. The full model is equivalent to the first model in a step-up/step-down analysis, or one-way analysis.</p>
<p>While it may seem retrogressive to report the results of an <code>lme4</code> analysis in the style of <em>Goldvarb</em>, presenting results in this fashion is highly readable and easily interpreted by other sociolinguistic researchers. Further, it is a succinct format for doing cross-model/data set comparisons. It also fulfills the requisites described by Gregory Guy in his <a href="http://gregoryrguy.com/wp-content/uploads/Guy-2018-Guidelines-for-reporting-quantitative-results-LVC-Nov-18-2018.pdf"><em>LVC guidelines for reporting quantitative results</em></a>. For example, <a href="#fig-gvtable2">Table&nbsp;3</a> compares the (t, d) deletion among young speakers with (t, d) deletion among middle/old speakers (see <a href="../../../content/R/lvc_r/040_lvcr.html">Modifying Data</a>). It very easily shows how the three lines of evidence are both similar and different between the two age cohorts. Representing this comparison using raw <code>lme4</code>/<code>glmer()</code> outputs (or tables resembling this output) would be harder to read and thus less immediately interpretable.</p>
<div id="fig-gvtable2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/gvtable2.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Table&nbsp;3: Mixed effects logistic regression analysis of the contribution of external and internal factors to the probability of /t, d/ -deletion in Cape Breton English for two age groups</figcaption><p></p>
</figure>
</div>
<p>From <a href="#fig-gvtable2">Table&nbsp;3</a> you can observe several patterns. Firstly, the overall probability of <code>Deletion</code> among young speakers is <span class="math inline">\(.41\)</span> and among middle/old speakers is <span class="math inline">\(.34\)</span>. This indicates that <code>Deletion</code> is more likely to occur among young speakers (though given that two measures of age are not significant when the data is combined suggests that this difference cannot be verified to be greater than chance variation). With respect to the first line of evidence (significance), you can see that for both age cohorts the same linguistic factors are significant predictors of the variation, indicating similar grammatical systems. Also important is that the same predictor, <code>Phoneme</code>, is not significant, also indicating similar grammatical systems. <code>Gender</code> is significant among middle/older speakers but not among younger speakers. This aligns with the findings from the <a href="../../../content/R/lvc_r/080_lvcr.html">Conditional Inference Tree</a>, which shows that older men delete at a greater rate than everyone else. You can see some difference between cohorts when you consider magnitude of effect. For both cohorts following context (<code>After.New</code>) has a greater magnitude of effect than stress or preceding context (<code>Before</code>). Morpheme type (<code>Morph.Type</code>), however, has a greater magnitude of effect among middle/older speakers relative to other predictors, while among younger speakers morpheme type has a lesser magnitude of effect compared to following context. This would be a pertinent finding to discuss in your manuscript. For the third line of evidence, constraint hierarchy, both cohorts have the same ranking of predictor levels for morpheme type, following context, stress, and, for the most part, preceding context. The one difference is preceding /s/, which highly favours deletion among younger speakers, but slightly disfavours deletion among older speakers. The one disadvantage of this <em>Goldvarb</em>-style table is that it does not show the individual, per-level significance measures. Looking at <code>td.glmer.not.young</code> below shows that the probability of <code>Deletion</code> among middle/older speakers’ preceding /s/ tokens is not statistically different from the mean. In other words, predicting /s/ is a strong favouring predictor of <code>Deletion</code> among young speakers, but an inconsequential predictor among middle/older speakers. When examining the <code>glmer()</code> outputs below, preceding /s/ is <code>Before4</code>. What the output of <code>td.glmer.not.young</code> also shows is that preceding other fricatives are also not significantly different from the mean. This suggests that for middle/older speakers /s/ and other fricatives behaving similarly, while for younger speakers /s/ and other fricatives do not behave similarly. We will delve into this phenomenon in <a href="../../../content/R/lvc_r/116_lvcr.html">Part 4</a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subset data</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>td.young <span class="ot">&lt;-</span> td <span class="sc">%&gt;%</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">subset</span>(Age.Group <span class="sc">==</span> <span class="st">"Young"</span>)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>td.not.young <span class="ot">&lt;-</span> td <span class="sc">%&gt;%</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">subset</span>(Age.Group <span class="sc">!=</span> <span class="st">"Young"</span>)</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create young speaker regression model</span></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>td.glmer.young <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td.young, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.young)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ After.New + Morph.Type + Before + Stress + Phoneme +  
    (1 | Speaker)
   Data: td.young
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
     609      662     -292      585      616 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-4.093 -0.488 -0.287  0.487  6.006 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.944    0.971   
Number of obs: 628, groups:  Speaker, 31

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -0.2631     0.2891   -0.91    0.363    
After.New1    1.6858     0.2189    7.70  1.3e-14 ***
After.New2   -1.2779     0.1926   -6.64  3.2e-11 ***
Morph.Type1   0.2434     0.1780    1.37    0.172    
Morph.Type2  -1.4470     0.2587   -5.59  2.2e-08 ***
Before1      -0.4411     0.2571   -1.72    0.086 .  
Before2       0.6435     0.2687    2.40    0.017 *  
Before3      -0.0946     0.3723   -0.25    0.799    
Before4       1.1065     0.2445    4.53  6.0e-06 ***
Stress1      -0.9500     0.1788   -5.31  1.1e-07 ***
Phoneme1      0.1545     0.1728    0.89    0.371    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) Aft.N1 Aft.N2 Mrp.T1 Mrp.T2 Befor1 Befor2 Befor3 Befor4
After.New1   0.071                                                        
After.New2  -0.139 -0.556                                                 
Morph.Type1 -0.298  0.251 -0.171                                          
Morph.Type2 -0.089 -0.205  0.199 -0.339                                   
Before1     -0.246 -0.132  0.255 -0.025  0.320                            
Before2     -0.128  0.237 -0.159 -0.124  0.238  0.070                     
Before3      0.213 -0.053 -0.019  0.241 -0.414 -0.439 -0.488              
Before4      0.126  0.359 -0.489 -0.031  0.049 -0.251 -0.018 -0.257       
Stress1     -0.394 -0.378  0.092  0.004  0.088  0.045 -0.039 -0.085 -0.269
Phoneme1     0.367  0.111 -0.249  0.041 -0.267 -0.467 -0.371  0.218  0.351
            Strss1
After.New1        
After.New2        
Morph.Type1       
Morph.Type2       
Before1           
Before2           
Before3           
Before4           
Stress1           
Phoneme1     0.009</code></pre>
</div>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create middle/old speaker regression model</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>td.glmer.not.young <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>    Phoneme <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td.not.young, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>),</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.not.young)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ After.New + Morph.Type + Before + Stress + Phoneme +  
    (1 | Speaker)
   Data: td.not.young
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
     508      560     -242      484      549 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-2.640 -0.467 -0.158  0.482 25.237 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.745    0.863   
Number of obs: 561, groups:  Speaker, 35

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -0.5123     0.3483   -1.47  0.14136    
After.New1    2.0614     0.2532    8.14  3.9e-16 ***
After.New2   -0.9225     0.2446   -3.77  0.00016 ***
Morph.Type1   0.8327     0.2706    3.08  0.00209 ** 
Morph.Type2  -2.6850     0.4202   -6.39  1.7e-10 ***
Before1      -0.8360     0.3555   -2.35  0.01869 *  
Before2       0.5781     0.3120    1.85  0.06392 .  
Before3       0.7617     0.4883    1.56  0.11875    
Before4       0.0656     0.3427    0.19  0.84817    
Stress1      -0.7591     0.2633   -2.88  0.00394 ** 
Phoneme1      0.2901     0.2159    1.34  0.17899    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) Aft.N1 Aft.N2 Mrp.T1 Mrp.T2 Befor1 Befor2 Befor3 Befor4
After.New1   0.136                                                        
After.New2  -0.019 -0.139                                                 
Morph.Type1 -0.624  0.091 -0.059                                          
Morph.Type2  0.073 -0.225  0.146 -0.491                                   
Before1     -0.356 -0.288  0.296  0.136  0.499                            
Before2     -0.151  0.156 -0.059 -0.116  0.247 -0.018                     
Before3     -0.075  0.061 -0.083  0.516 -0.669 -0.355 -0.449              
Before4      0.470  0.204 -0.319 -0.478  0.111 -0.381 -0.144 -0.350       
Stress1     -0.484 -0.557 -0.327  0.159  0.065  0.078  0.218 -0.034 -0.253
Phoneme1     0.589  0.206 -0.308 -0.375 -0.191 -0.622 -0.126 -0.018  0.567
            Strss1
After.New1        
After.New2        
Morph.Type1       
Morph.Type2       
Before1           
Before2           
Before3           
Before4           
Stress1           
Phoneme1    -0.200</code></pre>
</div>
</div>
<p>Despite how useful a <em>Goldvarb</em>-style table is, it is not the only way to report the results you’ve produced. Nor is the estimate the only information you have. There are other interesting values in your <code>summary(td.glmer)</code> output. Going left to right, after the estimate there is the standard error, the <span class="math inline">\(z\)</span>-value and the <span class="math inline">\(p\)</span>-value. According to Gregory Guy in his <a href="http://gregoryrguy.com/wp-content/uploads/Guy-2018-Guidelines-for-reporting-quantitative-results-LVC-Nov-18-2018.pdf"><em>LVC guidelines for reporting quantitative results</em></a>, reporting the estimates, standard errors, and significance is desirable. Whether reporting the <span class="math inline">\(z\)</span>-scores is required is unclear. <a href="#fig-lme4table">Table&nbsp;4</a> reports <code>td.glmer</code> in a format more similar to the <code>lme4</code> output. The likelihoods in <a href="#fig-lme4table">Table&nbsp;4</a> are presented in log odds. They correspond exactly to the probabilities in <a href="#fig-gvtable1">Table&nbsp;2</a>. One addition to the information in the <code>lme4</code> output included in <a href="#fig-lme4table">Table&nbsp;4</a> is the Observation columns. It is very important to report these distributions by factor/parameter level, preferably in your table, or somewhere else in your manuscript.</p>
<p>You also may want to report in your table additional measures of model fit (<span class="math inline">\(R^2\)</span>) and whether the model is an improvement over the null model.</p>
<div id="fig-lme4table" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/lme4table.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Table&nbsp;4: Mixed effects logistic regression analysis of the contribution of external and internal factors to the probability of /t, d/ -deletion in Cape Breton English for two age groups</figcaption><p></p>
</figure>
</div>


<!-- -->

</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Based on the random forest analysis performed in <a href="../../../content/R/lvc_r/090_lvcr.html">Random Forests: The Basics</a>, you know that <code>After</code> does a better job of explaining the variation than <code>After.New</code>; however, you want to make your analysis comparable to analyses in the sociolinguistic literature that do not single out pre-/h/ contexts. See also <em>Re-coding Variables</em> in <a href="../../../content/R/lvc_r/040_lvcr.html">Modifying Your Data</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Again, the random forest analysis (<a href="../../../content/R/lvc_r/090_lvcr.html">Random Forests: The Basics</a>) indicated that <code>Job</code> will do a better job; however, I am specifically interested in education level, so I choose this variable instead.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>It is also possible to include interaction groups in the model. For example, you could include the interaction group (<code>Age_Sex</code>), or you could tell <em>R</em> to make an <em>ad hoc</em> interaction group by specifying <code>Age*Sex</code> as a predictor in the model. I won’t discuss interactions here, but you can learn all about them from the very well-written <em>Notes on Interactions</em> by Derek Denis, available <a href="Data/Denis_2010_Notes_On_Interactions.pdf">here</a>. They are also discussed in <a href="../../../content/R/lvc_r/114_lvcr.html">Part 3</a>. The interpretation of interaction groups for <em>Rbrul</em> and in a sum contrast <code>glmer()</code> models is identical.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Equivalent to <span class="math inline">\(-2 \times\)</span> <code>logLik</code><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Equal to the sample size (e.g., the number of tokens, <span class="math inline">\(1189\)</span>) minus the number of parameters being estimated in the model (levels of the fixed effect predictors plus the intercept).<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>As is generally the convention since Sir Ronald Fischer (1925) said it should be. <span class="math inline">\(p&gt;0.05\)</span>, or 5% probability that the null hypotheses is true, corresponds to allowing as much as about two standard deviations of acceptable variation before rejecting the null hypothesis. Said another way, this threshold means the null hypothesis will be false <span class="math inline">\(19\)</span> times out of <span class="math inline">\(20\)</span>. See also <a href="http://www.radford.edu/%7Ejaspelme/611/Spring-2007/Cowles-n-Davis_Am-Psyc_orignis-of-05-level.pdf">Cowles &amp; Davis (1982)</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><div>CC-BY-SA 4.0</div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{huntgardner,
  author = {Matt Hunt Gardner},
  title = {Mixed-Efects {Logistic} {Regression} {Analysis:} {Part} 2},
  series = {Linguistics Methods Hub},
  volume = {Doing LVC with R},
  date = {},
  url = {https://lingmethodshub.github.io/112_lvcr.html},
  doi = {10.5281/zenodo.7160718},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-huntgardner" class="csl-entry quarto-appendix-citeas" role="doc-biblioentry">
Matt Hunt Gardner. n.d. Mixed-Efects Logistic Regression Analysis: Part
2. <em>Linguistics Methods Hub</em>: <em>Doing LVC with R</em>. (<a href="https://lingmethodshub.github.io/112_lvcr.html">https://lingmethodshub.github.io/112_lvcr.html</a>).
doi: <a href="https://doi.org/10.5281/zenodo.7160718">10.5281/zenodo.7160718</a>
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../content/R/lvc_r/110_lvcr.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Mixed-Efects Logistic Regression Analysis: Part 1</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../content/R/lvc_r/114_lvcr.html" class="pagination-link">
        <span class="nav-page-text">Mixed-Efects Logistic Regression Analysis: Part 3</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb94" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Mixed-Efects Logistic Regression Analysis: Part 2"</span></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "`r Sys.Date()`"</span></span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="an">license:</span><span class="co"> "CC-BY-SA 4.0"</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a><span class="co">    code-overflow: scroll</span></span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a><span class="co"># pdf: default</span></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - name:</span></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a><span class="co">      given: Matt Hunt</span></span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a><span class="co">      family: Gardner</span></span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-1878-4232</span></span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a><span class="co">    email: matt.gardner@ling-phil.ox.ac.uk</span></span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a><span class="co">    corresponding: true</span></span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: University of Oxford </span></span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a><span class="co">        department: Linguistics, Philology, &amp; Phonetics</span></span>
<span id="cb94-19"><a href="#cb94-19" aria-hidden="true" tabindex="-1"></a><span class="co">        city: Oxford</span></span>
<span id="cb94-20"><a href="#cb94-20" aria-hidden="true" tabindex="-1"></a><span class="co">        country: UK</span></span>
<span id="cb94-21"><a href="#cb94-21" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Doing a mixed-effects logistic regression analysis suitable for comparing to a *Goldvarb* analysis. Part 2: Sum Contrast Coding"</span></span>
<span id="cb94-22"><a href="#cb94-22" aria-hidden="true" tabindex="-1"></a><span class="an">crossref:</span></span>
<span id="cb94-23"><a href="#cb94-23" aria-hidden="true" tabindex="-1"></a><span class="co">  fig-title: Table  </span></span>
<span id="cb94-24"><a href="#cb94-24" aria-hidden="true" tabindex="-1"></a><span class="co">  fig-prefix: Table</span></span>
<span id="cb94-25"><a href="#cb94-25" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb94-26"><a href="#cb94-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-27"><a href="#cb94-27" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, include=FALSE}</span></span>
<span id="cb94-28"><a href="#cb94-28" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">echo =</span> <span class="cn">TRUE</span>)</span>
<span id="cb94-29"><a href="#cb94-29" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">tidy=</span><span class="st">'styler'</span>, <span class="at">tidy.opts=</span><span class="fu">list</span>(<span class="at">strict=</span><span class="cn">TRUE</span>, <span class="at">scope=</span><span class="st">"tokens"</span>), <span class="at">tidy =</span> <span class="cn">TRUE</span>)</span>
<span id="cb94-30"><a href="#cb94-30" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-31"><a href="#cb94-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-32"><a href="#cb94-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include=FALSE}</span></span>
<span id="cb94-33"><a href="#cb94-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb94-34"><a href="#cb94-34" aria-hidden="true" tabindex="-1"></a>td <span class="ot">&lt;-</span> <span class="fu">read.delim</span>(<span class="st">"Data/deletiondata.txt"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb94-35"><a href="#cb94-35" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(Before <span class="sc">!=</span> <span class="st">"Vowel"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb94-36"><a href="#cb94-36" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">After.New =</span> <span class="fu">recode</span>(After, <span class="st">"H"</span> <span class="ot">=</span> <span class="st">"Consonant"</span>),  </span>
<span id="cb94-37"><a href="#cb94-37" aria-hidden="true" tabindex="-1"></a>             <span class="at">Center.Age =</span> <span class="fu">as.numeric</span>(<span class="fu">scale</span>(YOB, <span class="at">scale =</span> <span class="cn">FALSE</span>)),</span>
<span id="cb94-38"><a href="#cb94-38" aria-hidden="true" tabindex="-1"></a>             <span class="at">Age.Group =</span> <span class="fu">cut</span>(YOB, <span class="at">breaks =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="cn">Inf</span>, <span class="dv">1944</span>, <span class="dv">1979</span>, <span class="cn">Inf</span>), </span>
<span id="cb94-39"><a href="#cb94-39" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Old"</span>, <span class="st">"Middle"</span>, <span class="st">"Young"</span>)),</span>
<span id="cb94-40"><a href="#cb94-40" aria-hidden="true" tabindex="-1"></a>             <span class="at">Phoneme =</span> <span class="fu">sub</span>(<span class="st">"^(.)(--.*)$"</span>, <span class="st">"</span><span class="sc">\\</span><span class="st">1"</span>, Phoneme.Dep.Var),</span>
<span id="cb94-41"><a href="#cb94-41" aria-hidden="true" tabindex="-1"></a>             <span class="at">Dep.Var.Full =</span> <span class="fu">sub</span>(<span class="st">"^(.--)(.*)$"</span>, <span class="st">"</span><span class="sc">\\</span><span class="st">2"</span>, Phoneme.Dep.Var),</span>
<span id="cb94-42"><a href="#cb94-42" aria-hidden="true" tabindex="-1"></a>             <span class="at">Phoneme.Dep.Var =</span> <span class="cn">NULL</span>) <span class="sc">%&gt;%</span></span>
<span id="cb94-43"><a href="#cb94-43" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate_if</span>(is.character, as.factor)</span>
<span id="cb94-44"><a href="#cb94-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-45"><a href="#cb94-45" aria-hidden="true" tabindex="-1"></a>td.young <span class="ot">&lt;-</span> td <span class="sc">%&gt;%</span> </span>
<span id="cb94-46"><a href="#cb94-46" aria-hidden="true" tabindex="-1"></a>            <span class="fu">filter</span>(Age.Group <span class="sc">==</span> <span class="st">"Young"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb94-47"><a href="#cb94-47" aria-hidden="true" tabindex="-1"></a>            <span class="fu">mutate</span>(<span class="at">Center.Age =</span> <span class="fu">as.numeric</span>(<span class="fu">scale</span>(YOB, <span class="at">scale =</span> <span class="cn">FALSE</span>)))</span>
<span id="cb94-48"><a href="#cb94-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-49"><a href="#cb94-49" aria-hidden="true" tabindex="-1"></a>td.middle <span class="ot">&lt;-</span> td <span class="sc">%&gt;%</span> </span>
<span id="cb94-50"><a href="#cb94-50" aria-hidden="true" tabindex="-1"></a>             <span class="fu">filter</span>(Age.Group <span class="sc">==</span> <span class="st">"Middle"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb94-51"><a href="#cb94-51" aria-hidden="true" tabindex="-1"></a>             <span class="fu">mutate</span>(<span class="at">Center.Age =</span> <span class="fu">as.numeric</span>(<span class="fu">scale</span>(YOB, <span class="at">scale =</span> <span class="cn">FALSE</span>)))</span>
<span id="cb94-52"><a href="#cb94-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-53"><a href="#cb94-53" aria-hidden="true" tabindex="-1"></a>td.old <span class="ot">&lt;-</span> td <span class="sc">%&gt;%</span> </span>
<span id="cb94-54"><a href="#cb94-54" aria-hidden="true" tabindex="-1"></a>          <span class="fu">filter</span>(Age.Group <span class="sc">==</span> <span class="st">"Old"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb94-55"><a href="#cb94-55" aria-hidden="true" tabindex="-1"></a>          <span class="fu">mutate</span>(<span class="at">Center.Age =</span> <span class="fu">as.numeric</span>(<span class="fu">scale</span>(YOB, <span class="at">scale =</span> <span class="cn">FALSE</span>)))</span>
<span id="cb94-56"><a href="#cb94-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-57"><a href="#cb94-57" aria-hidden="true" tabindex="-1"></a>td<span class="sc">$</span>Dep.Var <span class="ot">&lt;-</span> <span class="fu">factor</span>(td<span class="sc">$</span>Dep.Var, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Realized"</span>, <span class="st">"Deletion"</span>))</span>
<span id="cb94-58"><a href="#cb94-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-59"><a href="#cb94-59" aria-hidden="true" tabindex="-1"></a><span class="fu"># Sum Contrasts (vs. mean)</span></span>
<span id="cb94-60"><a href="#cb94-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-61"><a href="#cb94-61" aria-hidden="true" tabindex="-1"></a>Before you proceed with this section, please make sure that you have your data loaded and modified based on the code <span class="co">[</span><span class="ot">here</span><span class="co">](050_lvcr.qmd)</span> and that <span class="in">`Dep.Var`</span> is <span class="co">[</span><span class="ot">re-coded such that `Deletion` is the second factor</span><span class="co">](110_lvcr.qmd)</span>. Next, you set the global *R* options to employ sum contrast coding. Now you are ready to create a mixed-effects logistic regression model that is comparable to the model produced by *Goldvarb*. </span>
<span id="cb94-62"><a href="#cb94-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-65"><a href="#cb94-65" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-66"><a href="#cb94-66" aria-hidden="true" tabindex="-1"></a> <span class="co"># Sum Coding (vs. mean)</span></span>
<span id="cb94-67"><a href="#cb94-67" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">contrasts=</span><span class="fu">c</span>(<span class="st">"contr.sum"</span>,<span class="st">"contr.poly"</span>))</span>
<span id="cb94-68"><a href="#cb94-68" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-69"><a href="#cb94-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-70"><a href="#cb94-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-71"><a href="#cb94-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-72"><a href="#cb94-72" aria-hidden="true" tabindex="-1"></a><span class="fu">## Building Your Model</span></span>
<span id="cb94-73"><a href="#cb94-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-74"><a href="#cb94-74" aria-hidden="true" tabindex="-1"></a>The next step is creating the mixed-effects model. The following code tests the fixed effects of preceding phonological context (<span class="in">`Before`</span>), following phonological context (<span class="in">`After.New`</span><span class="ot">[^1]</span>), morphological status (<span class="in">`Morph.Type`</span>), lexical stress of the syllable (<span class="in">`Stress`</span>), underlying phoneme (<span class="in">`Phoneme`</span>), speaker age (<span class="in">`Centre.Age`</span>), speaker sex (<span class="in">`Sex`</span>) and speaker education level (<span class="in">`Education`</span><span class="ot">[^2]</span>), on the deletion of (t ,d) in the data set. It also takes into account the potential random effect of speaker (<span class="in">`Speaker`</span><span class="ot">[^3]</span>). The function for creating this model, <span class="in">`glmer()`</span> (for Generalized Linear Mixed Effects model with Random effects, what I call the "glimmer" <span class="sc">\[</span>glɪmɚ<span class="sc">\]</span> function) is part of the <span class="in">`lme4`</span> package.</span>
<span id="cb94-75"><a href="#cb94-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-76"><a href="#cb94-76" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>Based on the random forest analysis performed in <span class="co">[</span><span class="ot">Random Forests: The Basics</span><span class="co">](090_lvcr.qmd)</span>, you know that <span class="in">`After`</span> does a better job of explaining the variation than <span class="in">`After.New`</span>; however, you want to make your analysis comparable to analyses in the sociolinguistic literature that do not single out pre-/h/ contexts. See also *Re-coding Variables* in <span class="co">[</span><span class="ot">Modifying Your Data</span><span class="co">](040_lvcr.qmd)</span>.</span>
<span id="cb94-77"><a href="#cb94-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-78"><a href="#cb94-78" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: </span>Again, the random forest analysis (<span class="co">[</span><span class="ot">Random Forests: The Basics</span><span class="co">](090_lvcr.qmd)</span>) indicated that <span class="in">`Job`</span> will do a better job; however, I am specifically interested in education level, so I choose this variable instead.</span>
<span id="cb94-79"><a href="#cb94-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-80"><a href="#cb94-80" aria-hidden="true" tabindex="-1"></a><span class="ot">[^3]: </span>It is also possible to include interaction groups in the model. For example, you could include the interaction group (<span class="in">`Age_Sex`</span>), or you could tell *R* to make an *ad hoc* interaction group by specifying `Age*Sex` as a predictor in the model. I won't discuss interactions here, but you can learn all about them from the very well-written *Notes on Interactions* by Derek Denis, available [here](Data/Denis_2010_Notes_On_Interactions.pdf). They are also discussed in [Part 3](114_lvcr.qmd).  The interpretation of interaction groups for *Rbrul* and in a sum contrast <span class="in">`glmer()`</span> models is identical.</span>
<span id="cb94-81"><a href="#cb94-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-82"><a href="#cb94-82" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-83"><a href="#cb94-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-84"><a href="#cb94-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Generalized linear mixed effects model with the fixed main effects of Before, After.New, Morph.Type, Stress, Phoneme, Centre.Age, Sex and Education, and the random effect of Speaker</span></span>
<span id="cb94-85"><a href="#cb94-85" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb94-86"><a href="#cb94-86" aria-hidden="true" tabindex="-1"></a>td.glmer <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> Before <span class="sc">+</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> Center.Age <span class="sc">+</span> Sex <span class="sc">+</span> Education <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-87"><a href="#cb94-87" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-88"><a href="#cb94-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-89"><a href="#cb94-89" aria-hidden="true" tabindex="-1"></a>As with the <span class="in">`ctree()`</span> function, you construct your <span class="in">`gmler()`</span> model by first specifying the dependent variable, here <span class="in">`Dep.Var`</span>, then using <span class="in">`~`</span> to indicate that everything to the right is a potential predictor of your dependent variable (e.g., the variable on the left varies as a function of the variables on the right). The predictors are separated by a <span class="in">`+`</span>. You specify that <span class="in">`Speaker`</span> is a random effect by enclosing it in <span class="in">`(1| )`</span>. Here the <span class="in">`1`</span> simply indicates the model's intercept. You are essentially telling *R* to assume a different intercept (i.e., baseline likelihood of <span class="in">`Deletion`</span>) for each level of <span class="in">`Speaker`</span>. This effectively resolves the non-independence that stems from having multiple tokens by the same speaker. If you wanted to include both speaker and word as random effects, assuming you had columns called <span class="in">`Speaker`</span> and <span class="in">`Word`</span>, you could specify <span class="in">`+ (1|Speaker) + (1|Word)`</span> in your function. If you do not want any random effects in your model, you cannot use <span class="in">`glmer()`</span>. Instead, you must use <span class="in">`glme()`</span>.</span>
<span id="cb94-90"><a href="#cb94-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-91"><a href="#cb94-91" aria-hidden="true" tabindex="-1"></a>After specifying your predictors, you indicate that <span class="in">`family = "binomial"`</span> because you are looking at the binary choice between <span class="in">`Deletion`</span> and <span class="in">`Realization`</span>. The specification <span class="in">`control = glmerControl(optCtrl = list(maxfun = 2e4), optimizer = "bobyqa")`</span> simply tweaks how many function evaluations the <span class="in">`glmer()`</span> optimizer will try before giving up and declaring non-convergence with an error message. You don't need to use these specifications. If you don't, you may get non-convergence warnings --- but even if you do, that isn't necessarily the end of the world. As long as the reason you're getting the the non-convergence warnings is NOT because of singletons or knockouts in some cells (as a good sociolinguist I know you've weeded all of these out based on your cross-tabs), a model with a non-convergence warning like <span class="in">`Model failed to converge with max|grad| = 0.0259806 (tol = 0.001, component 1)`</span> will still yield explanatory, albeit sub-optimal, test statistic values.</span>
<span id="cb94-92"><a href="#cb94-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-93"><a href="#cb94-93" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="false"}</span>
<span id="cb94-94"><a href="#cb94-94" aria-hidden="true" tabindex="-1"></a><span class="fu">## What causes non-convergence?</span></span>
<span id="cb94-95"><a href="#cb94-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-96"><a href="#cb94-96" aria-hidden="true" tabindex="-1"></a>There are several things that will cause the model not to converge (i.e., fail). The first (and most common cause) is that your model is too complex. Complexity arises from having too many potential predictors or too many levels within each predictor. This complexity is more pernicious if your data set is small. Tweaking the <span class="in">`glmer()`</span> controls can help, but it won't always overcome extreme complexity. The first step, then, when dealing with non-convergence is thinking (from a theoretical perceptive) how you can simplify your model. Using a <span class="co">[</span><span class="ot">Conditional Inference Tree</span><span class="co">](080_lvcr.qmd)</span> or <span class="co">[</span><span class="ot">Random Forest</span><span class="co">](090_lvcr.qmd)</span> analyses can help --- so can a really thorough exploration of you data using <span class="co">[</span><span class="ot">cross tabs</span><span class="co">](060_lvcr.qmd)</span>. Cross-tabs especially can help you find whether you have **singletons** or **knockouts**. These terms are hold-overs from *Goldvarb* for phenomena in your data that can cause non-convergence, but they can also cause non-convergence in a <span class="in">`glmer()`</span> model. </span>
<span id="cb94-97"><a href="#cb94-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-98"><a href="#cb94-98" aria-hidden="true" tabindex="-1"></a>The following will cause non-convergence or skewed results in your regression analysis. :</span>
<span id="cb94-99"><a href="#cb94-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-100"><a href="#cb94-100" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**singleton** --- a single-level predictor variable and/or its one level. In the partition <span class="in">`td.young`</span> the predictor <span class="in">`Age.Group`</span> is a singleton because the only value is <span class="in">`Young`</span>. Solution: don't include this predictor in your model.</span>
<span id="cb94-101"><a href="#cb94-101" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**knockout** --- when a level of a predictor variable always (100% of tokens) or never (0% tokens) occurs with the application value of the dependent variable.  Solution: don't include this level in your model (but account for it in your description of the data), or re-code in a thoeortetically-motivated way.</span>
<span id="cb94-102"><a href="#cb94-102" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb94-103"><a href="#cb94-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-104"><a href="#cb94-104" aria-hidden="true" tabindex="-1"></a>In the code above you used the <span class="in">`&lt;-`</span> function to assign your model to the object  <span class="in">`td.glmer`</span>. To see the results of the model, use the <span class="in">`summary()`</span> function on the model object.</span>
<span id="cb94-105"><a href="#cb94-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-108"><a href="#cb94-108" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-109"><a href="#cb94-109" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer)</span>
<span id="cb94-110"><a href="#cb94-110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-111"><a href="#cb94-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-112"><a href="#cb94-112" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interpreting Your Model, Getting Constraint Hierarchy</span></span>
<span id="cb94-113"><a href="#cb94-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-114"><a href="#cb94-114" aria-hidden="true" tabindex="-1"></a>Now that you have the model, what does it tell you? There are all sorts of details in the <span class="in">`summary(td.glmer)`</span> output, but we're first just going to focus on the the first few lines.</span>
<span id="cb94-115"><a href="#cb94-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-116"><a href="#cb94-116" aria-hidden="true" tabindex="-1"></a>The beginning of the output simply tells you that you've completed a <span class="in">`Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod]`</span>. This is just name of the function you've just executed.</span>
<span id="cb94-117"><a href="#cb94-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-118"><a href="#cb94-118" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb94-119"><a href="#cb94-119" aria-hidden="true" tabindex="-1"></a><span class="fu">## Wait, I thought we were doing logistic regression?</span></span>
<span id="cb94-120"><a href="#cb94-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-121"><a href="#cb94-121" aria-hidden="true" tabindex="-1"></a>We are. See <span class="co">[</span><span class="ot">here</span><span class="co">](https://psyteachr.github.io/stat-models-v1/generalized-linear-mixed-effects-models.html)</span>.</span>
<span id="cb94-122"><a href="#cb94-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-123"><a href="#cb94-123" aria-hidden="true" tabindex="-1"></a>The basic idea behind **Generalized Linear Models** (not to be confused with General Linear Models) is to specify a **link function** that transforms the response space into a modelling space where we can perform a linear regression, and to capture the dependence of the variance on the mean through a **variance function**. A **Logistic regression**, then, is simply a linear regression analysis of binary data that has been first converted to the logit scale (thus making it "logistic") and for which the variance function is the variance of the **binomial** distribution.</span>
<span id="cb94-124"><a href="#cb94-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-125"><a href="#cb94-125" aria-hidden="true" tabindex="-1"></a>The key to understanding why we do this is that linear regression predicts the relationship between continuous, unbounded variables. This means that if we model the likelihood of a binary variable (e.g., $0$ vs. $1$) using linear regression, the model will predict scenarios where the variable could be lower than $0$ or higher than $1$. This motivates the conversion of the binary variable onto the logit scale.</span>
<span id="cb94-126"><a href="#cb94-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-127"><a href="#cb94-127" aria-hidden="true" tabindex="-1"></a>Usually we express the probability of the application value occurring as a proportion (number of tokens of the application value/total number of tokens). This proportion is bounded by $0$ and $1$. We can also talk about the odds of the application value occurring, which is the ratio of application vales to non-application values. Odds ratios, like proportions, are also bounded on one end, ranging from $1$ to $+\infty$. Odds ratios, however, can be converted to the logit scale (making them log odds), which allows us to consider this likelihood of the application value on a continuous scale (log odds range from $-\infty$ to $+\infty$).</span>
<span id="cb94-128"><a href="#cb94-128" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb94-129"><a href="#cb94-129" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb94-130"><a href="#cb94-130" aria-hidden="true" tabindex="-1"></a><span class="fu">## Probability, Odds Ratios &amp; Logg Odds</span></span>
<span id="cb94-131"><a href="#cb94-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-132"><a href="#cb94-132" aria-hidden="true" tabindex="-1"></a>Probability, odds ratios, and log odds are all the same thing, just expressed in different ways. It's similar to the idea of scientific notation: the number $1,000$ can be written as $1.0\times 10^3$ or even $10\times 10\times 10$.</span>
<span id="cb94-133"><a href="#cb94-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-134"><a href="#cb94-134" aria-hidden="true" tabindex="-1"></a>**Probability** is the probability that an event happens, i.e., that a token is the application value. For example, there are $1189$ tokens, of which $386$ are <span class="in">`Deletion`</span>. The proportion of deletion is $386/1189$ or approximately $0.32$. This means any given token has a $32\%$ chance of being a <span class="in">`Deletion`</span> token.</span>
<span id="cb94-135"><a href="#cb94-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-136"><a href="#cb94-136" aria-hidden="true" tabindex="-1"></a>**Odds** (more technically the odds of success) is defined as probability of success divided by the probability of failure. So the odds of a token being the application value ($32\%$ chance of `Deletion`) has an accompanying odds of failure ($68\%$ chance of `Realization`). Odds can be expressed as the ratio between these two, or as an **Odds Ratio**: $0.32/0.68$ or approximately $0.47$</span>
<span id="cb94-137"><a href="#cb94-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-138"><a href="#cb94-138" aria-hidden="true" tabindex="-1"></a>**Log odds** is the (natural) <span class="co">[</span><span class="ot">logarithm</span><span class="co">](https://www.statisticshowto.com/integrals/integral-natural-log-logarithms/)</span> of the odds: $log_e(0.47) = -0.75$. A logarithm is just another way to express an exponent: $log_e(0.47) = -0.75$ is identical to $e^{-0.75} = 0.47$, where $e$ is <span class="co">[</span><span class="ot">Euler's number</span><span class="co">]</span>(https://en.wikipedia.org/wiki/E_(mathematical_constant)), which is a mathematical constant used for this purpose (the first few numbers of which are $2.718$). Converting probabilities or odds ratios to log odds results in symmetry around zero, as shown in the following table <span class="co">[</span><span class="ot">(Jaccard, 2001)</span><span class="co">](https://books.google.com/books?id=tj1Wn5u9gSMC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false)</span>:</span>
<span id="cb94-139"><a href="#cb94-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-140"><a href="#cb94-140" aria-hidden="true" tabindex="-1"></a>| Probability | Odds Ratio | Log Odds |</span>
<span id="cb94-141"><a href="#cb94-141" aria-hidden="true" tabindex="-1"></a>|-------------|------------|----------|</span>
<span id="cb94-142"><a href="#cb94-142" aria-hidden="true" tabindex="-1"></a>| $0.100$       | $0.111$      | $-2.197$   |</span>
<span id="cb94-143"><a href="#cb94-143" aria-hidden="true" tabindex="-1"></a>| $0.200$       | $0.250$      | $-1.386$   |</span>
<span id="cb94-144"><a href="#cb94-144" aria-hidden="true" tabindex="-1"></a>| $0.300$       | $0.428$      | $-0.847$   |</span>
<span id="cb94-145"><a href="#cb94-145" aria-hidden="true" tabindex="-1"></a>| $0.400$       | $0.667$      | $-0.405$   |</span>
<span id="cb94-146"><a href="#cb94-146" aria-hidden="true" tabindex="-1"></a>| $0.500$       | $1.000$      | $0.000$    |</span>
<span id="cb94-147"><a href="#cb94-147" aria-hidden="true" tabindex="-1"></a>| $0.600$       | $1.500$      | $0.406$    |</span>
<span id="cb94-148"><a href="#cb94-148" aria-hidden="true" tabindex="-1"></a>| $0.700$       | $2.333$      | $0.847$    |</span>
<span id="cb94-149"><a href="#cb94-149" aria-hidden="true" tabindex="-1"></a>| $0.800$       | $4.000$      | $1.386$    |</span>
<span id="cb94-150"><a href="#cb94-150" aria-hidden="true" tabindex="-1"></a>| $0.900$       | $9.000$      | $2.197$    |</span>
<span id="cb94-151"><a href="#cb94-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-152"><a href="#cb94-152" aria-hidden="true" tabindex="-1"></a>See also <span class="ot">&lt;https://www.statisticshowto.com/log-odds/&gt;</span>.</span>
<span id="cb94-153"><a href="#cb94-153" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb94-154"><a href="#cb94-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-155"><a href="#cb94-155" aria-hidden="true" tabindex="-1"></a>The next lines of the <span class="in">`summary(td.glmer)`</span> output is tells you the variance function <span class="in">`Family: binomial`</span> and the link function <span class="in">`(logit)`</span> and the formula used to construct the model <span class="in">`Formula: Dep.Var ~ Before + After.New + Morph.Type + Stress + Phoneme + Center.Age + Sex + Education + (1 | Speaker)`</span>. Next is the data <span class="in">`Data: td`</span> and the tweak you've made to the controls: <span class="in">`Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")`</span>. This information is not new to you because it's exactly what you specified.</span>
<span id="cb94-156"><a href="#cb94-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-157"><a href="#cb94-157" aria-hidden="true" tabindex="-1"></a>You are then given some measures of model fit, including <span class="co">[</span><span class="ot">`AIC`</span><span class="co">](https://en.wikipedia.org/wiki/Akaike_information_criterion)</span>, <span class="co">[</span><span class="ot">`BIC`</span><span class="co">](https://en.wikipedia.org/wiki/Bayesian_information_criterion)</span>, <span class="in">`logLik`</span> (log likelihood), and <span class="in">`deviance`</span>.<span class="ot">[^4]</span> These values measure how well your model predicts the actual values of your data. They are measures of prediction error. This is similar to the log-likelihood reported by *Goldvarb*. Higher values for these measures indicate a worse fit to the data, lower values indicate a better fit to the data. Following these measures you are given the degrees of freedom of the residuals <span class="in">`df.resid`</span><span class="ot">[^5]</span> and then descriptors of the scaled residuals (<span class="in">`Min`</span>, <span class="in">`Max`</span>, and <span class="in">`Mean`</span> values and 1st and 3rd quartiles, <span class="in">`1Q`</span> and <span class="in">`3Q`</span>). The scaled residuals are simply a description of the variation that is not predicted by the model, or rather, the difference between the predicted and observed results. In large data sets these residuals should be <span class="co">[</span><span class="ot">normally distributed</span><span class="co">](https://en.wikipedia.org/wiki/Normal_distribution)</span>. These measures/residuals are more important for statisticians aiming to craft a model with the best possible fit to the data. They are also somewhat fuzzy to interpret for logistic regression modelling. For your purposes, where the goal is instead to test hypotheses or confirm trends, the goodness of fit of your model or the extent to which is explains all the data is only relevant insofar as it allows you to select the model built with the independent predictors (which you've selected to include in your analysis based of good theoretical linguistic/social reasoning) that best explain the variation. In other words, for you, a good model is not one that best fits the data, but rather that is the most sociolinguistically explanatory --- that tells the story of the variation in the best possible way.</span>
<span id="cb94-158"><a href="#cb94-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-159"><a href="#cb94-159" aria-hidden="true" tabindex="-1"></a><span class="ot">[^4]: </span>Equivalent to $-2 \times$ <span class="in">`logLik`</span> </span>
<span id="cb94-160"><a href="#cb94-160" aria-hidden="true" tabindex="-1"></a><span class="ot">[^5]: </span>Equal to the sample size (e.g., the number of tokens, $1189$) minus the number of parameters being estimated in the model (levels of the fixed effect predictors plus the intercept).</span>
<span id="cb94-161"><a href="#cb94-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-162"><a href="#cb94-162" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="false"}</span>
<span id="cb94-163"><a href="#cb94-163" aria-hidden="true" tabindex="-1"></a><span class="fu">## Which model is best?</span></span>
<span id="cb94-164"><a href="#cb94-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-165"><a href="#cb94-165" aria-hidden="true" tabindex="-1"></a>Including all the independent predictors you want to test is called creating a **full model** or **maximal model**. Once you start removing un-informative independent predictors from your model, or pruning it, you are entering the territory of model selection, which is as much an art as it is a science. Some statisticians recommend reporting on the full/maximal model, others (like [Bates, Kleigl, Vasishth,and Baayen 2018](https://doi.org/10.48550/arXiv.1506.04967)) argue for reporting the most **parsimonious** or the least complex maximally predictive model. Depending on your goals, you may choose to report one or the other. For example, the maximal model may be useful when comparing the same regression analysis across multiple partitions/data sets.</span>
<span id="cb94-166"><a href="#cb94-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-167"><a href="#cb94-167" aria-hidden="true" tabindex="-1"></a>Comparing measures of model fit can be useful when you have two potential predictors that are non-orthogonal (not independent) like education and employment type. You would not include both education and employment type in the same model because in many communities these two factors are not independent of each other. In Cape Breton, for example, white collar workers have higher education levels than blue collar workers. Including only one in a model is usually fine given that both are proxies for social status anyway. But which one do you choose to include?</span>
<span id="cb94-168"><a href="#cb94-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-169"><a href="#cb94-169" aria-hidden="true" tabindex="-1"></a>One way to choose is to construct two identical models, one with <span class="in">`Education`</span>, one with <span class="in">`Job`</span>, and then compare how well each fits the data. If, for example, the model with <span class="in">`Education`</span> fits the data better, you could argue that education level does a better job of explaining the variation than employment type. You could use this same strategy if you wanted to compare models with different coding schemes for certain parameters (like <span class="in">`After`</span> and <span class="in">`After.New`</span>).</span>
<span id="cb94-170"><a href="#cb94-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-171"><a href="#cb94-171" aria-hidden="true" tabindex="-1"></a>Comparing goodness of fit is not as easy as just comparing <span class="in">`AIC`</span> or <span class="in">`BIC`</span>, etc. though. Often values of goodness of fit measures that are very similar across models may in fact not be significantly different from one another given the differing number of parameter levels in each model. For example, the AIC of the most parsimonious model above constructed with <span class="in">`After`</span> instead of <span class="in">`After.New`</span> is $1049.9$ ($13$ parameters). The <span class="in">`AIC`</span> of the model constructed with <span class="in">`After.New`</span> (which you'll remember groups pre-/h/ contexts with other pre-consonantal contexts in order to compare with past research, see <span class="co">[</span><span class="ot">Modifying Data</span><span class="co">](040_lvcr.qmd)</span>) is $1113.8$ ($12$ parameters). This lower <span class="in">`AIC`</span> with <span class="in">`After`</span> indicates that this model is a better fit to the data than the model constructed with <span class="in">`After.New`</span>. This is unsurprising given that /h/ disfavours <span class="in">`Deletion`</span>, but other consonants do not (see the <span class="co">[</span><span class="ot">Conditional Inference Tree analysis</span><span class="co">](080_lvcr.qmd)</span>). The difference between the <span class="in">`AIC`</span> of the two models (given the difference of 1 parameter between them, i.e., degrees of freedom/df = 1) is statistically significantly greater than zero ( <span class="in">`Pr(&gt;Chisq) = 4.645e-16`</span> or $4.645\times 10^{-16}$, i.e., $p&lt;0.05$,). This can be determined using the function <span class="in">`anova(td.glmer1, td.glmer2)`</span> where <span class="in">`td.glmer1`</span> and <span class="in">`td.glmer2`</span> are the same model, but with one using <span class="in">`After`</span> and the other using <span class="in">`After.New`</span>. Note that relevant function is <span class="in">`anova()`</span>, which is used for comparing models, and not <span class="in">`Anova()`</span>, which is used for evaluating the significance of fixed effects in a model.</span>
<span id="cb94-172"><a href="#cb94-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-175"><a href="#cb94-175" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-176"><a href="#cb94-176" aria-hidden="true" tabindex="-1"></a>td.glmer1 <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-177"><a href="#cb94-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-178"><a href="#cb94-178" aria-hidden="true" tabindex="-1"></a>td.glmer2 <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-179"><a href="#cb94-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-180"><a href="#cb94-180" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(td.glmer1, td.glmer2)</span>
<span id="cb94-181"><a href="#cb94-181" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-182"><a href="#cb94-182" aria-hidden="true" tabindex="-1"></a>You can visualize the model fit using the <span class="co">[</span><span class="ot">`binnedplot()`</span><span class="co">](https://cran.r-project.org/web/packages/arm/arm.pdf)</span> function from the <span class="in">`arm`</span> package. </span>
<span id="cb94-183"><a href="#cb94-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-184"><a href="#cb94-184" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arm)</span>
<span id="cb94-185"><a href="#cb94-185" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="fu">predict</span>(td.glmer1)</span>
<span id="cb94-186"><a href="#cb94-186" aria-hidden="true" tabindex="-1"></a>y<span class="ot">&lt;-</span><span class="fu">resid</span>(td.glmer1)</span>
<span id="cb94-187"><a href="#cb94-187" aria-hidden="true" tabindex="-1"></a><span class="fu">binnedplot</span>(x,y)</span>
<span id="cb94-188"><a href="#cb94-188" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-189"><a href="#cb94-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-190"><a href="#cb94-190" aria-hidden="true" tabindex="-1"></a>In logistic regression, as with linear regression, the residuals are just the difference between the actual values and the values predicted by the model. Since the dependent variable is binary, the residuals will be binary too (either $1$ or $0$), so plotting the raw residuals is not really that informative. The binned residuals plot above divides the data into categories (bins) based on their fitted (predicted) values and then plots the average residual versus the average fitted value for each bin. In the plot the grey lines indicate plus and minus $2$ standard-error bounds. We expect about $95\%$ of the binned residuals (black dots) to fall between the two grey lines if the model is actually true. By default, for data sets larger than $100$ tokens, the number of bins is the square root of the total number of tokens. You can play with the number of bins with the option <span class="in">`nclass=`</span>. </span>
<span id="cb94-191"><a href="#cb94-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-192"><a href="#cb94-192" aria-hidden="true" tabindex="-1"></a>Compare the two binned residual plots (above and below). You can see that for the <span class="in">`td.glmer2`</span> residual plot there are more black dots outside the grey lines, indicating an inferior fit. </span>
<span id="cb94-193"><a href="#cb94-193" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-194"><a href="#cb94-194" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arm)</span>
<span id="cb94-195"><a href="#cb94-195" aria-hidden="true" tabindex="-1"></a>x<span class="ot">&lt;-</span><span class="fu">predict</span>(td.glmer2)</span>
<span id="cb94-196"><a href="#cb94-196" aria-hidden="true" tabindex="-1"></a>y<span class="ot">&lt;-</span><span class="fu">resid</span>(td.glmer2)</span>
<span id="cb94-197"><a href="#cb94-197" aria-hidden="true" tabindex="-1"></a><span class="fu">binnedplot</span>(x,y)</span>
<span id="cb94-198"><a href="#cb94-198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-199"><a href="#cb94-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-200"><a href="#cb94-200" aria-hidden="true" tabindex="-1"></a>We can do the same thing, but instead testing the difference between models built using a discrete age predictor: <span class="in">`Age.Group`</span>, versus a continuous age predictor: <span class="in">`Center.Age`</span>.</span>
<span id="cb94-201"><a href="#cb94-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-204"><a href="#cb94-204" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-205"><a href="#cb94-205" aria-hidden="true" tabindex="-1"></a>td.glmer3 <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> Center.Age <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-206"><a href="#cb94-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-207"><a href="#cb94-207" aria-hidden="true" tabindex="-1"></a>td.glmer4 <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> Age.Group <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-208"><a href="#cb94-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-209"><a href="#cb94-209" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(td.glmer3, td.glmer4)</span>
<span id="cb94-210"><a href="#cb94-210" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-211"><a href="#cb94-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-212"><a href="#cb94-212" aria-hidden="true" tabindex="-1"></a>The results of this <span class="in">`anova()`</span> show that the difference in fit of a model built with <span class="in">`Center.Age`</span> (<span class="in">`AIC`</span> $= 1051.0$) and <span class="in">`Age.Group`</span> (<span class="in">`AIC`</span> $= 1052.9$) is not significant (<span class="in">`Pr(&gt;Chisq) = 0.7619`</span>, or $p&gt;0.05$), or rather, the choice between the two is inconsequential to modelling the variation in the data.</span>
<span id="cb94-213"><a href="#cb94-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-214"><a href="#cb94-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-215"><a href="#cb94-215" aria-hidden="true" tabindex="-1"></a>In may also be useful to report in your manuscript that a model built with your fixed effects does a better job at predicting the variation than a model built with just the random effects (i.e., a **null model**). To make this comparison you build a model with no fixed effects and compare that using the <span class="in">`anova()`</span> function to your model with fixed effects. </span>
<span id="cb94-218"><a href="#cb94-218" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-219"><a href="#cb94-219" aria-hidden="true" tabindex="-1"></a>td.glmer.null <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span> ))</span>
<span id="cb94-220"><a href="#cb94-220" aria-hidden="true" tabindex="-1"></a>                      </span>
<span id="cb94-221"><a href="#cb94-221" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(td.glmer1, td.glmer.null)</span>
<span id="cb94-222"><a href="#cb94-222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-223"><a href="#cb94-223" aria-hidden="true" tabindex="-1"></a>In a manuscript you would report that the model built with fixed effect predictors and the random effect of <span class="in">`Speaker`</span> (<span class="in">`AIC`</span>$=1049.9$) does a significantly better job at predicting the variation in the data than a null model built with just the random effect of  <span class="in">`Speaker`</span> (<span class="in">`AIC`</span>$=1455.8$; $\chi^2=437.86$, $\text{df}=11$, $p&lt;0.001$). </span>
<span id="cb94-224"><a href="#cb94-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-225"><a href="#cb94-225" aria-hidden="true" tabindex="-1"></a>An additional measure of the success of your model is the $R^2$ value. This value tells you the proportion of the variability of the dependent variable that is explained by the independent predictors collectively. $R^2$ squared is a useful metric for multiple linear regression and as such is often requested by reviewers. But $R^2$ does not have the same meaning for logistic regression (binary dependant variables) as it does for linear regression (continuous dependant variables).  Statisticians have come up with a variety of analogues of $R^2$ squared for multiple logistic regression referred to collectively as "pseudo $R^2$". Given that there are multiple methods of calculating $R^2$, and that its use for non-linear models is still debated by statisticians, use and report it with a grain of salt. </span>
<span id="cb94-226"><a href="#cb94-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-227"><a href="#cb94-227" aria-hidden="true" tabindex="-1"></a>The easiest way to calculate a (pseudo-)*R^2* value using the <span class="co">[</span><span class="ot">Nakagawa &amp; Schielzeth's (2012)</span><span class="co">](https://doi.org/10.1111/j.2041-210x.2012.00261.x)</span> method is to use the function <span class="in">`r.squaredGLMM()`</span> from the <span class="in">`MuMIn`</span> package. </span>
<span id="cb94-228"><a href="#cb94-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, eval=FALSE}</span></span>
<span id="cb94-229"><a href="#cb94-229" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"MuMIn"</span>)</span>
<span id="cb94-230"><a href="#cb94-230" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb94-231"><a href="#cb94-231" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, warning =FALSE, message=FALSE}</span></span>
<span id="cb94-232"><a href="#cb94-232" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MuMIn)</span>
<span id="cb94-233"><a href="#cb94-233" aria-hidden="true" tabindex="-1"></a><span class="fu">r.squaredGLMM</span>(td.glmer)</span>
<span id="cb94-234"><a href="#cb94-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-235"><a href="#cb94-235" aria-hidden="true" tabindex="-1"></a>The <span class="in">`r.squaredGLMM()`</span> function returns a matrix with two calculations each for <span class="in">`R2m`</span> and <span class="in">`R2c`</span>. The first, <span class="in">`R2m`</span> or the marginal *R^2* value, represents the variance explained by the fixed effects alone. The function calculates this using two different methods. You can just look at the `theoretical`  calculation. It tells you that `0.43` or $43\%$ of the variance is explained by the fixed effects. The second set of values, the `R2c` or the conditional *R^2* value, represents the variance that is explained by the fixed effects plus the random effects. Here <span class="in">`0.52`</span> or $53\%$ of the variance is explained by the combination of fixed and random effects. </span>
<span id="cb94-236"><a href="#cb94-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-237"><a href="#cb94-237" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb94-238"><a href="#cb94-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-239"><a href="#cb94-239" aria-hidden="true" tabindex="-1"></a>::: callout-warning</span>
<span id="cb94-240"><a href="#cb94-240" aria-hidden="true" tabindex="-1"></a>You cannot meaningfully compare model fit across different data sets. Identical tokens and an identical dependant variable must be included in the two models being compared.  This is equally true for comparing AIC and $R^2$. </span>
<span id="cb94-241"><a href="#cb94-241" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb94-242"><a href="#cb94-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-243"><a href="#cb94-243" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random Effects {#sec-randomeffects}</span></span>
<span id="cb94-244"><a href="#cb94-244" aria-hidden="true" tabindex="-1"></a>After the measures of model fit is information about the random effects. In <span class="in">`td.glmer`</span> there is only one random effect: <span class="in">`Speaker`</span>. It is listed under <span class="in">`Groups`</span> because the model groups data by <span class="in">`Speaker`</span>. The <span class="in">`(Intercept)`</span> is listed under <span class="in">`Name`</span> because the model allows for variation of the <span class="in">`(Intercept)`</span> (i.e., baseline likelihood) by level of <span class="in">`Speaker`</span>. The likelihood of <span class="in">`Deletion`</span> for all levels of <span class="in">`Speaker`</span> considered together is found below under <span class="in">`Fixed Effect`</span>. It is the <span class="in">`Estimate`</span> value of <span class="in">`(Intercept)`</span>, e.g., <span class="in">`-0.255733`</span> log odds. The <span class="in">`Variance`</span> and the <span class="in">`Std.Dev`</span> are two different ways of expressing how much the levels of <span class="in">`Speaker`</span> vary around this baseline value.  The <span class="in">`Std.Dev`</span> is simply the square root of the <span class="in">`Variance`</span> ($\sqrt{0.6459} = 0.8036$. There is no consensus among sociolinguistics as to whether to report the value for <span class="in">`Variance`</span> or <span class="in">`Std.Dev`</span>. I prefer <span class="in">`Std.Dev`</span> because it is the same units as the <span class="in">`(Intercept)`</span>. In a manuscript you can therefore report that the overall baseline probability of the <span class="in">`td.glmer`</span> model is $-0.255788$ log odds ($\pm 0.806$ log odds, by speaker). </span>
<span id="cb94-245"><a href="#cb94-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-246"><a href="#cb94-246" aria-hidden="true" tabindex="-1"></a>Since we assume these likelihoods are normally-distributed, $95\%$ of the speakers' likelihoods will be within two standard deviations around the overall likelihood. We can calculate this using simple addition and subtraction, or we can calculate the range using an idealized normal distribution (using <span class="in">`qqnorm()`</span>). The results of these two calculations are slightly different as they are derived using somewhat different mathematical operations. For your purposes, just choose one method and stick with it. To make your calculations easier you can assign the overall likelihood and random effects standard deviation to their own variables.</span>
<span id="cb94-247"><a href="#cb94-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-250"><a href="#cb94-250" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-251"><a href="#cb94-251" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating the 95% range for a normal distribution on the logit scale</span></span>
<span id="cb94-252"><a href="#cb94-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-253"><a href="#cb94-253" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign overall likelihood and random effect standard deviations to their own variables</span></span>
<span id="cb94-254"><a href="#cb94-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-255"><a href="#cb94-255" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.255788</span></span>
<span id="cb94-256"><a href="#cb94-256" aria-hidden="true" tabindex="-1"></a>td.rsd <span class="ot">&lt;-</span> <span class="fl">0.8036</span></span>
<span id="cb94-257"><a href="#cb94-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-258"><a href="#cb94-258" aria-hidden="true" tabindex="-1"></a><span class="co"># or</span></span>
<span id="cb94-259"><a href="#cb94-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-260"><a href="#cb94-260" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="ot">&lt;-</span> <span class="fu">fixef</span>(td.glmer)[<span class="dv">1</span>]</span>
<span id="cb94-261"><a href="#cb94-261" aria-hidden="true" tabindex="-1"></a>td.rsd <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">unlist</span>(<span class="fu">VarCorr</span>(td.glmer)))</span>
<span id="cb94-262"><a href="#cb94-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-263"><a href="#cb94-263" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate +/- 2 standard deviations using a mathematical formula, lower then higher</span></span>
<span id="cb94-264"><a href="#cb94-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-265"><a href="#cb94-265" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>td.rsd</span>
<span id="cb94-266"><a href="#cb94-266" aria-hidden="true" tabindex="-1"></a>td.intercept <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>td.rsd</span>
<span id="cb94-267"><a href="#cb94-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-268"><a href="#cb94-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-269"><a href="#cb94-269" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the 95% range (2.5% to 97.5%) using an idealized normal distribution on the logit scale</span></span>
<span id="cb94-270"><a href="#cb94-270" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.025</span>,<span class="fl">0.975</span>),<span class="at">mean=</span>td.intercept, <span class="at">sd=</span>td.rsd)</span>
<span id="cb94-271"><a href="#cb94-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-272"><a href="#cb94-272" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-273"><a href="#cb94-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-274"><a href="#cb94-274" aria-hidden="true" tabindex="-1"></a>The results of the calculations are reported in log odds. It may be more interpretable to report these values as probabilities. </span>
<span id="cb94-275"><a href="#cb94-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-276"><a href="#cb94-276" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb94-277"><a href="#cb94-277" aria-hidden="true" tabindex="-1"></a><span class="fu">## Converting betweeen Log Odds and Probabilities (Factor Weights)</span></span>
<span id="cb94-278"><a href="#cb94-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-279"><a href="#cb94-279" aria-hidden="true" tabindex="-1"></a>*Goldvarb* reports **factor weights**, which are expressed as probabilities; the `glmer()` function reports **log odds**.</span>
<span id="cb94-280"><a href="#cb94-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-281"><a href="#cb94-281" aria-hidden="true" tabindex="-1"></a>To convert probabilities to log odds use the logit formula $x=log(\frac{p}{1-p})$, where $p$ is the probability and $x$ is the log odds value. It is much easier, however, to just use the <span class="in">`logit()`</span> function.</span>
<span id="cb94-282"><a href="#cb94-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-283"><a href="#cb94-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include=FALSE}</span></span>
<span id="cb94-284"><a href="#cb94-284" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb94-285"><a href="#cb94-285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-286"><a href="#cb94-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-287"><a href="#cb94-287" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-288"><a href="#cb94-288" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb94-289"><a href="#cb94-289" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert probabilities to log odds</span></span>
<span id="cb94-290"><a href="#cb94-290" aria-hidden="true" tabindex="-1"></a><span class="fu">logit</span>(<span class="fl">0.400</span>)</span>
<span id="cb94-291"><a href="#cb94-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-292"><a href="#cb94-292" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-293"><a href="#cb94-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-294"><a href="#cb94-294" aria-hidden="true" tabindex="-1"></a>To convert log odds to probabilities you can use the inverse logit formula $p=\frac{e^x}{(1+e^x)}$, or the <span class="in">`inv.logit()`</span> function from the <span class="in">`boot`</span> package. (If you've still got the <span class="in">`car`</span> package loaded from earlier you may need to reload the <span class="in">`boot`</span> package.)</span>
<span id="cb94-295"><a href="#cb94-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-296"><a href="#cb94-296" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-297"><a href="#cb94-297" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert log odds to probabilities</span></span>
<span id="cb94-298"><a href="#cb94-298" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(boot)</span>
<span id="cb94-299"><a href="#cb94-299" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="sc">-</span><span class="fl">0.405</span>)</span>
<span id="cb94-300"><a href="#cb94-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-301"><a href="#cb94-301" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb94-302"><a href="#cb94-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-303"><a href="#cb94-303" aria-hidden="true" tabindex="-1"></a>Based on the second calculations, you can report in a manuscript that the mean baseline probability of <span class="in">`Deletion`</span> in the data is $44\%$ and that the $95\%$ range for individual speakers' baseline probabilities is $14\%$ to $79\%$.</span>
<span id="cb94-306"><a href="#cb94-306" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-307"><a href="#cb94-307" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% range converted to probabilities</span></span>
<span id="cb94-308"><a href="#cb94-308" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.025</span>,<span class="fl">0.975</span>),<span class="at">mean=</span>td.intercept, <span class="at">sd=</span>td.rsd))</span>
<span id="cb94-309"><a href="#cb94-309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-310"><a href="#cb94-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-311"><a href="#cb94-311" aria-hidden="true" tabindex="-1"></a>To get the baseline likelihood for individual speakers you can extract the random effect values using <span class="in">`ranef()`</span>. </span>
<span id="cb94-314"><a href="#cb94-314" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-315"><a href="#cb94-315" aria-hidden="true" tabindex="-1"></a><span class="co"># Get individual baseline likelihoods by speaker</span></span>
<span id="cb94-316"><a href="#cb94-316" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(td.glmer)</span>
<span id="cb94-317"><a href="#cb94-317" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-318"><a href="#cb94-318" aria-hidden="true" tabindex="-1"></a>For each individual speaker you add their random effect value to the overall baseline likelihood to get that speaker's baseline likelihood. The baseline likelihood of <span class="in">`Deletion`</span> for speaker <span class="in">`ARSM91`</span> is $32\%$. </span>
<span id="cb94-321"><a href="#cb94-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-322"><a href="#cb94-322" aria-hidden="true" tabindex="-1"></a><span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker[<span class="st">"ARSM91"</span>,]</span>
<span id="cb94-323"><a href="#cb94-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-324"><a href="#cb94-324" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker[<span class="st">"ARSM91"</span>,], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>] )</span>
<span id="cb94-325"><a href="#cb94-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-326"><a href="#cb94-326" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">sum</span>(<span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker[<span class="st">"ARSM91"</span>,], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>] ))</span>
<span id="cb94-327"><a href="#cb94-327" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-328"><a href="#cb94-328" aria-hidden="true" tabindex="-1"></a>Below is a series of functions that extracts the coefficient (in log-odds) of the  random intercept for each speaker and then adds next to those coefficients the frequency of the application value for each speaker, as well as that speaker's total number of tokens. Finally it orders the speakers from lowest to highest random effect intercept coefficient. There is also an extra step to specify the order of the <span class="in">`Dep.Var`</span> factor because the following <span class="in">`table()}`</span> function specifies the level to extract by number and you want to make sure that is <span class="in">`Deletion`</span>.</span>
<span id="cb94-329"><a href="#cb94-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-332"><a href="#cb94-332" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-333"><a href="#cb94-333" aria-hidden="true" tabindex="-1"></a><span class="co"># Create column of Speakers with intercept coefficient</span></span>
<span id="cb94-334"><a href="#cb94-334" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb94-335"><a href="#cb94-335" aria-hidden="true" tabindex="-1"></a>td.ranef <span class="ot">&lt;-</span><span class="fu">add_rownames</span>(<span class="fu">as.data.frame</span>(<span class="fu">ranef</span>(td.glmer)<span class="sc">$</span>Speaker), <span class="st">"Speaker"</span>)</span>
<span id="cb94-336"><a href="#cb94-336" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(td.ranef)[<span class="dv">2</span>]<span class="ot">&lt;-</span><span class="st">"Intercept"</span></span>
<span id="cb94-337"><a href="#cb94-337" aria-hidden="true" tabindex="-1"></a><span class="co"># Reorder levels of Dep.Var to make application value second</span></span>
<span id="cb94-338"><a href="#cb94-338" aria-hidden="true" tabindex="-1"></a>td<span class="sc">$</span>Dep.Var <span class="ot">&lt;-</span> <span class="fu">factor</span>(td<span class="sc">$</span>Dep.Var, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Realized"</span>, <span class="st">"Deletion"</span>))</span>
<span id="cb94-339"><a href="#cb94-339" aria-hidden="true" tabindex="-1"></a> <span class="co"># Create column of Frequencies</span></span>
<span id="cb94-340"><a href="#cb94-340" aria-hidden="true" tabindex="-1"></a>speaker.prop <span class="ot">&lt;-</span><span class="fu">add_rownames</span>(<span class="fu">as.data.frame</span>(<span class="fu">prop.table</span>(<span class="fu">table</span>(td<span class="sc">$</span>Speaker, td<span class="sc">$</span>Dep.Var),<span class="dv">1</span>)[,<span class="dv">2</span>]), <span class="st">"Speaker"</span>)</span>
<span id="cb94-341"><a href="#cb94-341" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(speaker.prop)[<span class="dv">2</span>] <span class="ot">&lt;-</span><span class="st">"Percent"</span></span>
<span id="cb94-342"><a href="#cb94-342" aria-hidden="true" tabindex="-1"></a><span class="co"># Create column of token counts</span></span>
<span id="cb94-343"><a href="#cb94-343" aria-hidden="true" tabindex="-1"></a>speaker.n <span class="ot">&lt;-</span><span class="fu">as.data.frame</span>(<span class="fu">table</span>(td<span class="sc">$</span>Speaker))</span>
<span id="cb94-344"><a href="#cb94-344" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(speaker.n)<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="st">"Speaker"</span>,<span class="st">"Total N"</span>)</span>
<span id="cb94-345"><a href="#cb94-345" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge column of frequencies and column of token counts with column of Speakers</span></span>
<span id="cb94-346"><a href="#cb94-346" aria-hidden="true" tabindex="-1"></a>td.ranef.speaker <span class="ot">&lt;-</span><span class="fu">merge</span>(td.ranef, speaker.prop, <span class="at">by =</span><span class="st">"Speaker"</span>)</span>
<span id="cb94-347"><a href="#cb94-347" aria-hidden="true" tabindex="-1"></a>td.ranef.speaker <span class="ot">&lt;-</span><span class="fu">merge</span>(td.ranef.speaker, speaker.n, <span class="at">by =</span><span class="st">"Speaker"</span>)</span>
<span id="cb94-348"><a href="#cb94-348" aria-hidden="true" tabindex="-1"></a><span class="co"># Order data from lowest to highest Intercept, reset/delete row names</span></span>
<span id="cb94-349"><a href="#cb94-349" aria-hidden="true" tabindex="-1"></a>td.ranef.speaker <span class="ot">&lt;-</span> td.ranef.speaker[<span class="fu">order</span>(td.ranef.speaker<span class="sc">$</span>Intercept, td.ranef.speaker<span class="sc">$</span>Percent),]</span>
<span id="cb94-350"><a href="#cb94-350" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(td.ranef.speaker) <span class="ot">&lt;-</span><span class="cn">NULL</span></span>
<span id="cb94-351"><a href="#cb94-351" aria-hidden="true" tabindex="-1"></a><span class="co"># Show final table, supress rownames</span></span>
<span id="cb94-352"><a href="#cb94-352" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(td.ranef.speaker, <span class="at">row.names=</span><span class="cn">FALSE</span>)</span>
<span id="cb94-353"><a href="#cb94-353" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-354"><a href="#cb94-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-355"><a href="#cb94-355" aria-hidden="true" tabindex="-1"></a>If you look at the top (<span class="in">`head()`</span>) and bottom (<span class="in">`tail()`</span>) of this new table you can see that speakers <span class="in">`LATF53`</span> and <span class="in">`LELM91`</span> are the most likely to produce fully-realized (t, d) (even though, in the case of <span class="in">`LATF53`</span>, the frequency of <span class="in">`Deletion`</span> is not the lowest), while <span class="in">`VICF91`</span> and <span class="in">`MARM92`</span> are the most likely to delete (t, d).  This is because the former have an overall higher baseline likelihood (<span class="in">`(Intercept)`</span>+ random effect estimate) and the latter have an overall lower baseline likelihood (<span class="in">`(Intercept)`</span> + random effect estimate). This information could be very useful to your analysis. </span>
<span id="cb94-358"><a href="#cb94-358" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-359"><a href="#cb94-359" aria-hidden="true" tabindex="-1"></a><span class="co"># Show first six rows of td.ranef.speaker</span></span>
<span id="cb94-360"><a href="#cb94-360" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(td.ranef.speaker)</span>
<span id="cb94-361"><a href="#cb94-361" aria-hidden="true" tabindex="-1"></a><span class="co"># Show last six rows of td.ranef.speaker</span></span>
<span id="cb94-362"><a href="#cb94-362" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(td.ranef.speaker)</span>
<span id="cb94-363"><a href="#cb94-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-364"><a href="#cb94-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-365"><a href="#cb94-365" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fixed Effects</span></span>
<span id="cb94-366"><a href="#cb94-366" aria-hidden="true" tabindex="-1"></a>Looking back again at <span class="in">`summary(td.glmer)`</span>, at the end of the details of the random effects you are presented with some useful information: <span class="in">`Number of obs: 1189, groups:  Speaker, 66`</span>. This tells you the total number of tokens in your data set: <span class="in">`1189`</span>, and the total number of speakers: <span class="in">`66`</span>.</span>
<span id="cb94-369"><a href="#cb94-369" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-370"><a href="#cb94-370" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer)</span>
<span id="cb94-371"><a href="#cb94-371" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-372"><a href="#cb94-372" aria-hidden="true" tabindex="-1"></a>Next you have the analysis of fixed effects. In the leftmost column you have a list of the levels of each parameter minus one. More on that in a moment. For each level there is an estimate value, also called the coefficient. This value, expressed in log odds, is like a factor weight. Unlike factor weights which are centred around $0.5$ and range from $0$ to $1$, log odds are centred around $0$ and range from $+\infty$ to $-\infty$. Parameter levels with positive polarity log odds favour the application value relative to that parameter's baseline likelihood. Parameter levels with negative polarity log odds disfavour the application value relative to that parameter's baseline likelihood.</span>
<span id="cb94-373"><a href="#cb94-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-374"><a href="#cb94-374" aria-hidden="true" tabindex="-1"></a>The coefficient for the <span class="in">`(Intercept)`</span>, as described above, is the overall baseline likelihood. It is the likelihood, all things being equal, that any given token will have the application value rather than the non-application value. It is the mean of the baseline likelihoods of all the parameters in the model. It is just like the input value reported in *Goldvarb*. You can also refer to it as the centred mean. This value is usually reported in your manuscript as a probability. You can use the <span class="in">`inv.logit()`</span> function to convert it to a probability (see above). </span>
<span id="cb94-375"><a href="#cb94-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-376"><a href="#cb94-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-377"><a href="#cb94-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-378"><a href="#cb94-378" aria-hidden="true" tabindex="-1"></a>After the <span class="in">`(Intercept)`</span> is the name of each predictor followed by a number (e.g., <span class="in">`Before1`</span>). Each number represents a different level of that predictor, but one level is missing. This is an annoying consequence of the <span class="in">`lme4`</span> package being built for the conventions of other disciplines where sum contrasts are less commonly used. The numbers correspond to the order of factors within the level. You can double-check this order using the function \texttt{levels()}</span>
<span id="cb94-379"><a href="#cb94-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-382"><a href="#cb94-382" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-383"><a href="#cb94-383" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the levels of a column Before</span></span>
<span id="cb94-384"><a href="#cb94-384" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(td<span class="sc">$</span>Before)</span>
<span id="cb94-385"><a href="#cb94-385" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-386"><a href="#cb94-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-387"><a href="#cb94-387" aria-hidden="true" tabindex="-1"></a>The levels will always be in alphabetical order unless you explicitly change them. In your results, <span class="in">`Before1`</span> is <span class="in">`Liquid`</span>, <span class="in">`Before2`</span> is <span class="in">`Nasal`</span>, <span class="in">`Before3`</span> is <span class="in">`Other Fricative`</span>, and <span class="in">`Before4`</span> is <span class="in">`S`</span>. The "missing" level is the last level, <span class="in">`Stop`</span>. Because the log odds for all levels of a parameter are centred around the mean, you can actually calculate the estimate/coefficient for this last level. The sum off all coefficients for a single parameter will equal zero. Therefore the coefficient of the missing level will be 0 minus the sum of all the remaining coefficients for that parameter. So the estimate for <span class="in">`Stop`</span> is:</span>
<span id="cb94-388"><a href="#cb94-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-389"><a href="#cb94-389" aria-hidden="true" tabindex="-1"></a>$$\begin{equation*}</span>
<span id="cb94-390"><a href="#cb94-390" aria-hidden="true" tabindex="-1"></a>0= <span class="co">[</span><span class="ot">\text{Before1}x + \text{Before2}x + \text{Before3}x + \text{Before4}x</span><span class="co">]</span> + \text{Missing Coefficient}<span class="sc">\\</span></span>
<span id="cb94-391"><a href="#cb94-391" aria-hidden="true" tabindex="-1"></a>\end{equation*}$$ </span>
<span id="cb94-392"><a href="#cb94-392" aria-hidden="true" tabindex="-1"></a>Thus...</span>
<span id="cb94-393"><a href="#cb94-393" aria-hidden="true" tabindex="-1"></a>$$\begin{equation*}</span>
<span id="cb94-394"><a href="#cb94-394" aria-hidden="true" tabindex="-1"></a>0- <span class="co">[</span><span class="ot">\text{Before1}x + \text{Before2}x + \text{Before3}x + \text{Before4}x</span><span class="co">]</span> =\text{Missing Coefficient}</span>
<span id="cb94-395"><a href="#cb94-395" aria-hidden="true" tabindex="-1"></a>\end{equation*}$$ </span>
<span id="cb94-396"><a href="#cb94-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-397"><a href="#cb94-397" aria-hidden="true" tabindex="-1"></a>We can extract the specific values using the <span class="in">`fixef()`</span> function and the position of the coefficients in the list.</span>
<span id="cb94-398"><a href="#cb94-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-401"><a href="#cb94-401" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-402"><a href="#cb94-402" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the coefficients for the fixed effects</span></span>
<span id="cb94-403"><a href="#cb94-403" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span>(td.glmer)</span>
<span id="cb94-404"><a href="#cb94-404" aria-hidden="true" tabindex="-1"></a><span class="co"># Subtract the sum of the coefficients from 0 by name</span></span>
<span id="cb94-405"><a href="#cb94-405" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="sc">-</span><span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="fu">c</span>(<span class="st">"Before1"</span>, <span class="st">"Before2"</span>, <span class="st">"Before3"</span>, <span class="st">"Before4"</span>)])</span>
<span id="cb94-406"><a href="#cb94-406" aria-hidden="true" tabindex="-1"></a><span class="co"># Subtract the sum of the coefficients from 0 more easily by position</span></span>
<span id="cb94-407"><a href="#cb94-407" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="sc">-</span><span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb94-408"><a href="#cb94-408" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-409"><a href="#cb94-409" aria-hidden="true" tabindex="-1"></a>Using the <span class="in">`inv.logit()`</span>  function, you can also calculate the probabilities (e.g., centered factor weights) for each of these parameter levels. We can adjust the number of significant digits so that *R* does your rounding automatically. </span>
<span id="cb94-410"><a href="#cb94-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-413"><a href="#cb94-413" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-414"><a href="#cb94-414" aria-hidden="true" tabindex="-1"></a><span class="co"># Set number of significant digits to 2</span></span>
<span id="cb94-415"><a href="#cb94-415" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits=</span><span class="dv">2</span>)</span>
<span id="cb94-416"><a href="#cb94-416" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Liquid</span></span>
<span id="cb94-417"><a href="#cb94-417" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before1"</span>])</span>
<span id="cb94-418"><a href="#cb94-418" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Nasal</span></span>
<span id="cb94-419"><a href="#cb94-419" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before2"</span>])</span>
<span id="cb94-420"><a href="#cb94-420" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Other Fricative</span></span>
<span id="cb94-421"><a href="#cb94-421" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before3"</span>])</span>
<span id="cb94-422"><a href="#cb94-422" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of S</span></span>
<span id="cb94-423"><a href="#cb94-423" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Before4"</span>])</span>
<span id="cb94-424"><a href="#cb94-424" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of Stop</span></span>
<span id="cb94-425"><a href="#cb94-425" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="dv">0</span><span class="sc">-</span><span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>]))</span>
<span id="cb94-426"><a href="#cb94-426" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-427"><a href="#cb94-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-428"><a href="#cb94-428" aria-hidden="true" tabindex="-1"></a>Based on this calculation you now know that the constraint hierarchy based on factor weight-like probabilities for preceding segment is <span class="in">`S`</span> ($0.67$) &gt; <span class="in">`Nasal`</span> ($0.63$) &gt;<span class="in">`Other Fricative`</span> ($0.53$) &gt; <span class="in">`Liquid`</span> ($0.36$) &gt; <span class="in">`Stop`</span> ($0.31$). An easier way to get these values is with the combination of <span class="in">`plogis()`</span>, which converts log odds to probabilities like <span class="in">`inv.logit()`</span>, and <span class="in">`fct_rev()`</span>, which reverses the order of factors. Re-creating <span class="in">`td.glmer`</span> with all parameter levels being reversed means the final/"missing" levels in <span class="in">`td.glmer`</span> are now the first levels. So, for <span class="in">`td.glmer.reversed`</span> we only look at <span class="in">`fct_rev(Before)1`</span>, <span class="in">`fct_rev(Morph.Type)1`</span>, etc. This is a quick way to get the values for the missing levels. </span>
<span id="cb94-431"><a href="#cb94-431" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-432"><a href="#cb94-432" aria-hidden="true" tabindex="-1"></a><span class="co"># Get probabilities for all estimates in td.glmer</span></span>
<span id="cb94-433"><a href="#cb94-433" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">fixef</span>(td.glmer))</span>
<span id="cb94-434"><a href="#cb94-434" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-create td.glmer with all parameters with reversed factor orders</span></span>
<span id="cb94-435"><a href="#cb94-435" aria-hidden="true" tabindex="-1"></a>td.glmer.reversed <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> <span class="fu">fct_rev</span>(Before) <span class="sc">+</span> <span class="fu">fct_rev</span>(After.New) <span class="sc">+</span> <span class="fu">fct_rev</span>(Morph.Type) <span class="sc">+</span> <span class="fu">fct_rev</span>(Stress) <span class="sc">+</span> <span class="fu">fct_rev</span>(Phoneme) <span class="sc">+</span> Center.Age <span class="sc">+</span> <span class="fu">fct_rev</span>(Sex) <span class="sc">+</span> Education <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-436"><a href="#cb94-436" aria-hidden="true" tabindex="-1"></a><span class="co"># Get probabilities for all estimates in td.glmer.reversed. Just looking at the first value (which corresponds to the final/missing value in td.glmer)</span></span>
<span id="cb94-437"><a href="#cb94-437" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">fixef</span>(td.glmer.reversed))</span>
<span id="cb94-438"><a href="#cb94-438" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-439"><a href="#cb94-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-440"><a href="#cb94-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-441"><a href="#cb94-441" aria-hidden="true" tabindex="-1"></a>These values are not the overall probability for each level, but rather centred probablity/factor weights. An estimate of $0$ log odds ($0.50$ probability) indicates the likelihood/probability for tokens of that predictor level is equal to the overall likelihood <span class="in">`(Intercept)`</span>. To get the actual probability for a given level, you have to add its estimate to the <span class="in">`(Intercept)`</span>. The overall likelihood for <span class="in">`Female`</span> (e.g.,<span class="in">`Sex1`</span>) tokens is thus  $-0.38$ log odds or $41\%$.</span>
<span id="cb94-444"><a href="#cb94-444" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-445"><a href="#cb94-445" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the estimate for Sex1 to the estimate for (Intercept)</span></span>
<span id="cb94-446"><a href="#cb94-446" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Sex1"</span>], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>])</span>
<span id="cb94-447"><a href="#cb94-447" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the sum of the estimates for Sex1 and (Intercept) to probability</span></span>
<span id="cb94-448"><a href="#cb94-448" aria-hidden="true" tabindex="-1"></a><span class="fu">inv.logit</span>(<span class="fu">sum</span>(<span class="fu">fixef</span>(td.glmer)[<span class="st">"Sex1"</span>], <span class="fu">fixef</span>(td.glmer)[<span class="st">"(Intercept)"</span>]))</span>
<span id="cb94-449"><a href="#cb94-449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-450"><a href="#cb94-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-451"><a href="#cb94-451" aria-hidden="true" tabindex="-1"></a>Returning now to the <span class="in">`summary(td.glmer)`</span>, in the second and third columns of the fixed effects, the standard error and $z$ value are reported. Both are used to calculate the estimate. Whether the difference in likelihood represented by the estimate/coefficient for each level is significantly different from zero (i.e., equal to the overall likelihood <span class="in">`(Intercept)`</span>) is also calculated using the standard error and is reported in the fourth column.  The <span class="in">`Pr(&gt;|z|)`</span> value is the probability that this difference is equal to zero. The asterisks indicate whether this probability is lower than increasingly smaller thresholds. Generally, in the humanities and social sciences we use $p&gt;0.05$ as our significance threshold,<span class="ot">[^6]</span> so anything with at least one asterisk is considered significant. For the levels of <span class="in">`Before`</span>, the coefficients for <span class="in">`Liquid`</span> (<span class="in">`Before1`</span>), <span class="in">`Nasal`</span> (<span class="in">`Before1`</span>), and <span class="in">`S`</span> (<span class="in">`Before4`</span>) are significantly different from zero. In other words, the likelihood of <span class="in">`Deletion`</span> for these tokens is significantly different from the baseline. This is not the case for <span class="in">`Other Fricative`</span> (<span class="in">`Before3`</span>) tokens. For the "missing" level, <span class="in">`Stop`</span>, you know that the coefficient/estimate is <span class="in">`-0.8020349596`</span> which is a greater negative number than the estimate for <span class="in">`Before1`</span>, so you can infer that this difference must also be significant. To verify you can reorder the levels of <span class="in">`Before`</span> such that <span class="in">`Stop`</span> is no longer the last factor. You can do this by creating a new column with reordered factors, or you can use the <span class="in">`fct_rev()`</span> function to do the same inside the <span class="in">`glmer()`</span> formula. </span>
<span id="cb94-452"><a href="#cb94-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-453"><a href="#cb94-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-454"><a href="#cb94-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-455"><a href="#cb94-455" aria-hidden="true" tabindex="-1"></a><span class="ot">[^6]: </span>As is generally the convention since Sir Ronald Fischer (1925) said it should be. $p&gt;0.05$, or 5% probability that the null hypotheses is true, corresponds to allowing as much as about two standard deviations of acceptable variation before rejecting the null hypothesis. Said another way, this threshold means the null hypothesis will be false $19$ times out of $20$. See also <span class="co">[</span><span class="ot">Cowles &amp; Davis (1982)</span><span class="co">](http://www.radford.edu/%7Ejaspelme/611/Spring-2007/Cowles-n-Davis_Am-Psyc_orignis-of-05-level.pdf)</span></span>
<span id="cb94-456"><a href="#cb94-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-459"><a href="#cb94-459" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-460"><a href="#cb94-460" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-order Before in reverse alphabetical order </span></span>
<span id="cb94-461"><a href="#cb94-461" aria-hidden="true" tabindex="-1"></a>td<span class="sc">$</span>Before.Reorder<span class="ot">&lt;-</span><span class="fu">factor</span>(td<span class="sc">$</span>Before, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Stop"</span>, <span class="st">"S"</span>, <span class="st">"Other Fricative"</span>, <span class="st">"Nasal"</span>, <span class="st">"Liquid"</span>))</span>
<span id="cb94-462"><a href="#cb94-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-463"><a href="#cb94-463" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-create td.glmer with reordered Before</span></span>
<span id="cb94-464"><a href="#cb94-464" aria-hidden="true" tabindex="-1"></a>td.glmer.reorder <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> Before.Reorder <span class="sc">+</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span></span>
<span id="cb94-465"><a href="#cb94-465" aria-hidden="true" tabindex="-1"></a>    Center.Age <span class="sc">+</span> Sex <span class="sc">+</span> Education <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb94-466"><a href="#cb94-466" aria-hidden="true" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-467"><a href="#cb94-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-468"><a href="#cb94-468" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative method </span></span>
<span id="cb94-469"><a href="#cb94-469" aria-hidden="true" tabindex="-1"></a>td.glmer.reorder <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> <span class="fu">fct_rev</span>(Before) <span class="sc">+</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span></span>
<span id="cb94-470"><a href="#cb94-470" aria-hidden="true" tabindex="-1"></a>    Center.Age <span class="sc">+</span> Sex <span class="sc">+</span> Education <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb94-471"><a href="#cb94-471" aria-hidden="true" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-472"><a href="#cb94-472" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.reorder)</span>
<span id="cb94-473"><a href="#cb94-473" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-474"><a href="#cb94-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-475"><a href="#cb94-475" aria-hidden="true" tabindex="-1"></a>You can see above that the coefficient/estimate for <span class="in">`Before.Reorder`</span>, which you know is <span class="in">`Stop`</span>, is <span class="in">`-0.80205`</span>--- nearly identical to what you calculated (the difference is due to rounding). You can see based on the value for <span class="in">`Pr(.|z|)`</span> that $p=2.2\times 10^{-5]}$, which is definitely lower than $0.05$, i.e., significant.</span>
<span id="cb94-476"><a href="#cb94-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-477"><a href="#cb94-477" aria-hidden="true" tabindex="-1"></a>For sum contrast coding, the <span class="in">`Pr(&gt;|z|)`</span> value for the <span class="in">`(Intercept)`</span> tells you whether the baseline likelihood is significantly different from $0$ --- but remember, $0$ log odds is equivalent to a probability of $50\%$ or a $50/50$ chance of a token being <span class="in">`Deletion`</span>. For the intercept here, the value is $-0.277$ log odds (or $44\%$ probability), which the model can't verify as being statistically significantly different from $0$ log odds ($50\%$ probability). </span>
<span id="cb94-478"><a href="#cb94-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-479"><a href="#cb94-479" aria-hidden="true" tabindex="-1"></a>Following the fixed effects there is usually a matrix of correlations. With many predictors or with predictors with many levels this correlation matrix can be very large. If the matrix is too large *R* will not print it automatically. Don't worry too much about the correlation matrix right now. We will return to it in <span class="co">[</span><span class="ot">Part 3</span><span class="co">](114_lvcr.qmd)</span>.</span>
<span id="cb94-480"><a href="#cb94-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-481"><a href="#cb94-481" aria-hidden="true" tabindex="-1"></a>::: {.callout-note collapse="true"}</span>
<span id="cb94-482"><a href="#cb94-482" aria-hidden="true" tabindex="-1"></a><span class="fu">## Visualizing the Fixed Effects </span></span>
<span id="cb94-483"><a href="#cb94-483" aria-hidden="true" tabindex="-1"></a>A useful way to visualize the fixed effects is with the function <span class="in">`plot_model()`</span> from the <span class="in">`sjPlot`</span>  and affiliated packages. You should have <span class="in">`ggplot2`</span> already installed if you've been following along. </span>
<span id="cb94-484"><a href="#cb94-484" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, eval=FALSE, message=FALSE}</span></span>
<span id="cb94-485"><a href="#cb94-485" aria-hidden="true" tabindex="-1"></a><span class="co"># Install sjPlot and affiliated pacakges</span></span>
<span id="cb94-486"><a href="#cb94-486" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">c</span>(<span class="st">"sjPlot"</span>, <span class="st">"sjlabelled"</span>, <span class="st">"sjmisc"</span>))</span>
<span id="cb94-487"><a href="#cb94-487" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-488"><a href="#cb94-488" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-489"><a href="#cb94-489" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required packages</span></span>
<span id="cb94-490"><a href="#cb94-490" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb94-491"><a href="#cb94-491" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjlabelled)</span>
<span id="cb94-492"><a href="#cb94-492" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjmisc)</span>
<span id="cb94-493"><a href="#cb94-493" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb94-494"><a href="#cb94-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-495"><a href="#cb94-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-496"><a href="#cb94-496" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects</span></span>
<span id="cb94-497"><a href="#cb94-497" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer)</span>
<span id="cb94-498"><a href="#cb94-498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-499"><a href="#cb94-499" aria-hidden="true" tabindex="-1"></a>In the plot the default *x*-axis is transformed to odds ratios. You'll remember that odds ratios are mathematically equivalent to both log odds and probabilities. To show either of these in plot, you can use the <span class="in">`transform=`</span> option, <span class="in">`NULL`</span> (no transformation) for log odds and <span class="in">`"plogis"`</span> for probabilities. </span>
<span id="cb94-502"><a href="#cb94-502" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-503"><a href="#cb94-503" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with log odds as the x-axis</span></span>
<span id="cb94-504"><a href="#cb94-504" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="cn">NULL</span>)</span>
<span id="cb94-505"><a href="#cb94-505" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with probabilities as the x-axis</span></span>
<span id="cb94-506"><a href="#cb94-506" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="st">"plogis"</span>)</span>
<span id="cb94-507"><a href="#cb94-507" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-508"><a href="#cb94-508" aria-hidden="true" tabindex="-1"></a>You'll see that for the log odds plot the values are centered around $0$ (no effect), which is equivalent to 1 odds ratio in the odds ratio plot, or $0.50$ probability in the probability plot.</span>
<span id="cb94-509"><a href="#cb94-509" aria-hidden="true" tabindex="-1"></a>The dots represent the estimate of the fixed effects. The lines extending to the right and left of the dots represent the bounds of the standard error. If the standard error does not cross the center line then the effect is statistically significant. The red dots in the log odds and odds ratio plots indicate values below the center line, red values indicate values below the center line. In the probability plot the values are all unfortunately red.  As with the output of the sum contrast <span class="in">`glmer()`</span> model, there is also unfortunately one "missing" value for each predictor. </span>
<span id="cb94-510"><a href="#cb94-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-511"><a href="#cb94-511" aria-hidden="true" tabindex="-1"></a>You can show the estimate values using the option <span class="in">`show.values = TRUE`</span>. Doing so also adds the significance asterisks (which can be suppressed, if desired, with <span class="in">`show.p = FALSE`</span>). The values will be plotted directly on top of the points, so use <span class="in">`value.offset`</span> to adjust the relative positioning. You can also highlight the center line with the <span class="in">`vline.color`</span> option. </span>
<span id="cb94-512"><a href="#cb94-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-515"><a href="#cb94-515" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-516"><a href="#cb94-516" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with log odds as the x-axis, estimates and significance showing, and highlighted center line</span></span>
<span id="cb94-517"><a href="#cb94-517" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="cn">NULL</span>, <span class="at">show.values =</span> <span class="cn">TRUE</span>, <span class="at">value.offset=</span><span class="fl">0.3</span>, <span class="at">vline.color=</span><span class="st">"black"</span>)</span>
<span id="cb94-518"><a href="#cb94-518" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-519"><a href="#cb94-519" aria-hidden="true" tabindex="-1"></a>You can see that all error bars that cross the center line are not significant. You can sort the individual levels of the predictors from most favouring to least favouring using the option <span class="in">`sort.est = TRUE`</span>. You can change the title using <span class="in">`title =`</span>. You can also make this graph readable in non-colored manuscripts using <span class="in">`color="bw"`</span> or <span class="in">`color = "gs"`</span> and employ some of the themes you encountered <span class="co">[</span><span class="ot">in previous chapters</span><span class="co">](070_lvcr.qmd)</span>.  Other tweaks to the plot can be found <span class="co">[</span><span class="ot">here</span><span class="co">](https://cran.r-project.org/web/packages/sjPlot/vignettes/plot_model_estimates.html)</span></span>
<span id="cb94-522"><a href="#cb94-522" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-523"><a href="#cb94-523" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot fixed effects with log odds as the x-axis, estimates and significance showing, highlighted center line, and sorted estimates</span></span>
<span id="cb94-524"><a href="#cb94-524" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">transform =</span> <span class="cn">NULL</span>, <span class="at">show.values =</span> <span class="cn">TRUE</span>, <span class="at">value.offset=</span><span class="fl">0.3</span>, <span class="at">vline.color=</span><span class="st">"black"</span>, <span class="at">sort.est=</span><span class="cn">TRUE</span>, <span class="at">title =</span> <span class="st">"Likelihood of (t,d) deletion"</span>, <span class="at">colors =</span> <span class="st">"gs"</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span>
<span id="cb94-525"><a href="#cb94-525" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-526"><a href="#cb94-526" aria-hidden="true" tabindex="-1"></a>While this type of plot may be less useful when reporting on a sum contrast regression analysis (as there are missing values), it is very useful when reporting on <span class="co">[</span><span class="ot">treatment contrast regression analyses</span><span class="co">](116_lvcr.qmd)</span>.  You can also plot the random effects per <span class="in">`Speaker`</span> by using the option <span class="in">`type = "rf"`</span>. This provides similar information as you extracted from the <span class="in">`glmer()`</span> model in @sec-randomeffects. To sort this plot by random effect estimate you also need to add <span class="in">`grid = FALSE`</span>.</span>
<span id="cb94-527"><a href="#cb94-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-528"><a href="#cb94-528" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.height=8}</span></span>
<span id="cb94-529"><a href="#cb94-529" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot random effects with log odds as the x-axis, estimates and significance showing, highlighted center line, and sorted estimates</span></span>
<span id="cb94-530"><a href="#cb94-530" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_model</span>(td.glmer, <span class="at">type =</span> <span class="st">"re"</span>, <span class="at">transform =</span> <span class="cn">NULL</span>, <span class="at">vline.color=</span><span class="st">"black"</span>, <span class="at">sort.est=</span><span class="st">"sort.all"</span>, <span class="at">grid=</span><span class="cn">FALSE</span>, <span class="at">title =</span> <span class="st">"Random effect per Speaker"</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span>
<span id="cb94-531"><a href="#cb94-531" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-532"><a href="#cb94-532" aria-hidden="true" tabindex="-1"></a>The above plot shows that, based on the standard error, only five speakers have baseline likelihoods of <span class="in">`Deletion`</span> significantly different from the overall intercept: <span class="in">`GARF37`</span> and <span class="in">`LATF53`</span> have a significantly lower baseline likelihood of <span class="in">`Deletion`</span>, while <span class="in">`VICF91`</span>, <span class="in">`MARM92`</span>, <span class="in">`NATF84`</span>, <span class="in">`INGM84`</span> and <span class="in">`HAWM90`</span> have a significantly higher baseline likelihood of deletion. </span>
<span id="cb94-533"><a href="#cb94-533" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb94-534"><a href="#cb94-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-535"><a href="#cb94-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-536"><a href="#cb94-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-537"><a href="#cb94-537" aria-hidden="true" tabindex="-1"></a><span class="fu">## Determining Significance and Magnitude of Effect</span></span>
<span id="cb94-538"><a href="#cb94-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-539"><a href="#cb94-539" aria-hidden="true" tabindex="-1"></a>Let's return now to the **three lines of evidence**. Does the model tell you which factors groups are significant predictors of the dependent variable? The answer: sort of. It tells you which levels of certain predictors are significantly different from the baseline, but this isn't the same thing as signalling which predictors, collectively, create the best (e.g., most explanatory) model of the variation --- the way *Goldvarb*'s step-up/step-down model does. In other words, you aren't provided with the first two lines of evidence. You can figure out the third line of evidence, constraint hierarchy, but this would be the constraint hierarchy in what could conceivably be an overstuffed model. What you need is a tool to determine which factors **should** be in the model --- or, rather, which factors actually explain the variation and which factors are erroneous. For this you can use the Wald $\chi^2$ test. The Wald $\chi^2$ test iteratively adds and removes each factor group/predictor, known as a parameter of the model, and compares how well each iteration fits the distribution of the data. If a parameter is found to be significant, it is interpreted as adding explanatory value. If a parameter is not significant, its contribution is superfluous to the understanding of the data and can be set aside. In this way, the Wald $\chi^2$ test is very similar to the step-up/step-up down procedure implemented by *Goldvarb*. The result of the Wald $\chi^2$ test reveals what combination of original parameters make the most parsimonious model, or rather, a group of original factors that only includes those that contribute significantly to predicting the variation.</span>
<span id="cb94-540"><a href="#cb94-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-541"><a href="#cb94-541" aria-hidden="true" tabindex="-1"></a>The Wald $\chi^2$ test is part of the <span class="in">`car`</span> package. The function, <span class="in">`Anova()`</span> is performed on an object, in this case <span class="in">`td.glmer`</span>, which is the result of a previously-performed logistic regression. Be careful, though! There is another function <span class="in">`anova()`</span>, which does not perform the Wald $\chi^2$ test and is instead used for comparing different models.</span>
<span id="cb94-542"><a href="#cb94-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-543"><a href="#cb94-543" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-544"><a href="#cb94-544" aria-hidden="true" tabindex="-1"></a><span class="co"># Wald Chi-Square test of most parsimonious model</span></span>
<span id="cb94-545"><a href="#cb94-545" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb94-546"><a href="#cb94-546" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(td.glmer)</span>
<span id="cb94-547"><a href="#cb94-547" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-548"><a href="#cb94-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-549"><a href="#cb94-549" aria-hidden="true" tabindex="-1"></a>The results of the Wald $\chi^2$ test gives you the first line of evidence. They show you which factor groups, or parameters, add explanatory value to the model and which don't. This is functionally equivalent to the selection of significant factors in a step-up/step-down procedure. The results also tell you the relative magnitude of effect of each parameter. The larger the $\chi^2$ statistic (<span class="in">`Chisq`</span>), the greater magnitude of effect. Using $p&gt;0.05$ as the cut-off you see that <span class="in">`Before`</span>, <span class="in">`After.New`</span>, <span class="in">`Morph.Type`</span>, <span class="in">`Stress`</span>, and <span class="in">`Phoneme`</span> all add explanatory value. <span class="in">`Centre.Age`</span>, <span class="in">`Sex`</span>, and <span class="in">`Education`</span> do not (unsurprising given the results of the <span class="co">[</span><span class="ot">Random Forest</span><span class="co">](090_lvcr.qmd)</span> analysis). This means that the finding that there is a division between men and women, and among men between those born before and after 1990 (as suggested by the <span class="co">[</span><span class="ot">Conditional Inference Tree</span><span class="co">](080_lvcr.qmd)</span> analysis), is in fact not real once you take the linguistic factors, and the random effect of speaker, into account. Put another way, you do not have statistical validation for the observed trend in the summary statistics. In the Wald $\chi^2$ results, <span class="in">`After.New`</span> has the largest $\chi^2$ value ($147.85$) indicating it has the largest magnitude of effect on the variation. This is functionally equivalent to saying that its factor weights have the largest range. In descending order you then have <span class="in">`Morph.Type`</span> ($\chi^2 = 77.77$), <span class="in">`Before`</span> ($\chi^2 = 38.67$), <span class="in">`Stress`</span> ($\chi^2 = 33.28$), and <span class="in">`Phoneme`</span> ($\chi^2 = 4.82$).</span>
<span id="cb94-550"><a href="#cb94-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-551"><a href="#cb94-551" aria-hidden="true" tabindex="-1"></a>Here is how you might represent these results in a manuscript:</span>
<span id="cb94-552"><a href="#cb94-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-553"><a href="#cb94-553" aria-hidden="true" tabindex="-1"></a><span class="al">![Analysis of deviance, Wald $\chi^2$ test for full model, Deletion of word-final (t, d) in Cape Breton English](images/waldtest.png)</span>{#fig-wald width="60%"}</span>
<span id="cb94-554"><a href="#cb94-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-555"><a href="#cb94-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-556"><a href="#cb94-556" aria-hidden="true" tabindex="-1"></a>The last line of evidence is the constraint hierarchy, or rather, the order of constraints from most favouring to least favouring. This last line of evidence in *Goldvarb* requires factor weights. Specifically, it requires the factor weights from the best step-up model and best step-down model --- which should match. To re-create the equivalent model you simply create the most parsimonious model identified by the Wald $\chi^2$ test. Here, that is a model constructed with only <span class="in">`After.New`</span>, <span class="in">`Morph.Type`</span>, <span class="in">`Before`</span>, <span class="in">`Stress`</span>, and <span class="in">`Phoneme`</span>.</span>
<span id="cb94-557"><a href="#cb94-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-558"><a href="#cb94-558" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb94-559"><a href="#cb94-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-560"><a href="#cb94-560" aria-hidden="true" tabindex="-1"></a><span class="co"># Most Parsimonious Model: Generalized linear mixed effects model with the fixed main effects of Before, After.New, Morph.Type, Stress, Phoneme, and the random effect of Speaker</span></span>
<span id="cb94-561"><a href="#cb94-561" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb94-562"><a href="#cb94-562" aria-hidden="true" tabindex="-1"></a>td.glmer.parsimonious <span class="ot">&lt;-</span><span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>Speaker), <span class="at">data =</span> td, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">control =</span> <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="fl">2e4</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-563"><a href="#cb94-563" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.parsimonious)</span>
<span id="cb94-564"><a href="#cb94-564" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-565"><a href="#cb94-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-566"><a href="#cb94-566" aria-hidden="true" tabindex="-1"></a><span class="fu">## Creating a Manuscript-ready Table</span></span>
<span id="cb94-567"><a href="#cb94-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-568"><a href="#cb94-568" aria-hidden="true" tabindex="-1"></a>The estimates or coefficients give us the last line of evidence --- and the last piece of statistical information that is generally reported in a standard *Goldvarb*-style manuscript table. @fig-gvtable1 is such a table constructed using the information from the <span class="in">`td.glmer.parsimonious`</span> regression analysis. </span>
<span id="cb94-569"><a href="#cb94-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-570"><a href="#cb94-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-571"><a href="#cb94-571" aria-hidden="true" tabindex="-1"></a><span class="al">![Mixed effects logistic regression analysis of the contribution of external and internal factors to the probability of /t, d/ -deletion in Cape Breton English](images/gvtable.png)</span>{#fig-gvtable1 width="80%"}</span>
<span id="cb94-572"><a href="#cb94-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-573"><a href="#cb94-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-574"><a href="#cb94-574" aria-hidden="true" tabindex="-1"></a>The *Input* is the estimate of the intercept, converted to a probability using the `inv.logit()` function. You can quickly get these values using `plogis(fixef(td.glmer.parsimonious))`. The *Total N*, frequencies and *n* counts for each factor come from the summary statistics you [performed earlier](060_lvcr.qmd). The factor weights for each factor are that factor's estimates converted to probabilities, again using the `inv.logit()`  or `plogis()` function. Any mixed-effects model with a random effect should report the random effect. *Speaker* is listed as a random effect, and the dispersion among speakers is reported. As noted above, there is no consensus around whether to report the <span class="in">`Variance`</span> or <span class="in">`Std.Dev`</span> as the measure of this dispersion (remember standard deviation is simply the square root of the variance). Here I've reported standard deviation. </span>
<span id="cb94-575"><a href="#cb94-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-578"><a href="#cb94-578" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-579"><a href="#cb94-579" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">fixef</span>(td.glmer.parsimonious))</span>
<span id="cb94-580"><a href="#cb94-580" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-581"><a href="#cb94-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-582"><a href="#cb94-582" aria-hidden="true" tabindex="-1"></a>The range for each factor group is the difference between the largest factor weight and the lowest factor weight expressed as a whole number. Notice that the ordering of magnitude of effect by the range of probabilities is slightly different from the ordering of magnitude of effect based on the $\chi^2$ coefficient from the Wald $\chi^2$ test and the ordering from the <span class="co">[</span><span class="ot">Random Forest</span><span class="co">](090_lvcr.qmd)</span> analysis.  For this reason it may be prudent to be very careful when using magnitude of effect/the second line of evidence to compare similarity/difference across data sets. Using multiple means to assess magnitude of effect is warranted, as is being very transparent about the means you use. </span>
<span id="cb94-583"><a href="#cb94-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-584"><a href="#cb94-584" aria-hidden="true" tabindex="-1"></a>Many who create *Goldvarb*-style tables using data from either *Rbrul* or *R*'s <span class="in">`glmer()`</span> function report both the log odds and factor weights for a given factor (e.g., <span class="co">[</span><span class="ot">Drummond 2012</span><span class="co">](https://doi.org/10.1017/S0954394512000026)</span>, Tables 3-8; <span class="co">[</span><span class="ot">Becker 2014</span><span class="co">](https://doi.org/10.1017/S0954394514000064)</span>, Tables 5-6, etc.). I have not done so in the @fig-gvtable1 because reporting both is redundant: probability (factor weights),  odds-ratios,  and likelihood (log odds) are functionally the same, and one can be derived from the other mathematically. Finally, if you wanted to report the factor weights, proportions, and token counts for non-significant factors you could do so (of course, following conventions of the field  by enclosing the factor weights in square brackets and not reporting the range) with values taken from the full (not most-parsimonious) model and the summary statistics. The full model is equivalent to the first model in a step-up/step-down analysis, or one-way analysis.</span>
<span id="cb94-585"><a href="#cb94-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-586"><a href="#cb94-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-587"><a href="#cb94-587" aria-hidden="true" tabindex="-1"></a>While it may seem retrogressive to report the results of an <span class="in">`lme4`</span> analysis in the style of *Goldvarb*, presenting results in this fashion is highly readable and easily interpreted by other sociolinguistic researchers. Further, it is a succinct format for doing cross-model/data set comparisons. It also fulfills the requisites described by Gregory Guy in his [*LVC guidelines for reporting quantitative results*](http://gregoryrguy.com/wp-content/uploads/Guy-2018-Guidelines-for-reporting-quantitative-results-LVC-Nov-18-2018.pdf). For example, @fig-gvtable2 compares the (t, d) deletion among young speakers with (t, d) deletion among middle/old speakers (see <span class="co">[</span><span class="ot">Modifying Data</span><span class="co">](040_lvcr.qmd)</span>). It very easily shows how the three lines of evidence are both similar and different between the two age cohorts. Representing this comparison using raw <span class="in">`lme4`</span>/<span class="in">`glmer()`</span> outputs (or tables resembling this output) would be harder to read and thus less immediately interpretable. </span>
<span id="cb94-588"><a href="#cb94-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-589"><a href="#cb94-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-590"><a href="#cb94-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-591"><a href="#cb94-591" aria-hidden="true" tabindex="-1"></a><span class="al">![Mixed effects logistic regression analysis of the contribution of external and internal factors to the probability of /t, d/ -deletion in Cape Breton English for two age groups](images/gvtable2.png)</span>{#fig-gvtable2 width="80%"}</span>
<span id="cb94-592"><a href="#cb94-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-593"><a href="#cb94-593" aria-hidden="true" tabindex="-1"></a>From @fig-gvtable2 you can observe several patterns. Firstly, the overall probability of <span class="in">`Deletion`</span> among young speakers is $.41$ and among middle/old speakers is $.34$. This indicates that <span class="in">`Deletion`</span> is more likely to occur among young speakers (though given that two measures of age are not significant when the data is combined suggests that this difference cannot be verified to be greater than chance variation). With respect to the first line of evidence (significance), you can see that for both age cohorts the same linguistic factors are significant predictors of the variation, indicating similar grammatical systems. Also important is that the same predictor, <span class="in">`Phoneme`</span>, is not significant, also indicating similar grammatical systems. <span class="in">`Gender`</span> is significant among middle/older speakers but not among younger speakers. This aligns with the findings from the <span class="co">[</span><span class="ot">Conditional Inference Tree</span><span class="co">](080_lvcr.qmd)</span>, which shows that older men delete at a greater rate than everyone else. You can see some difference between cohorts when you consider magnitude of effect. For both cohorts following context (<span class="in">`After.New`</span>) has a greater magnitude of effect than stress or preceding context (<span class="in">`Before`</span>). Morpheme type (<span class="in">`Morph.Type`</span>), however, has a greater magnitude of effect among middle/older speakers relative to other predictors, while among younger speakers morpheme type has a lesser magnitude of effect compared to following context. This would be a pertinent finding to discuss in your manuscript. For the third line of evidence, constraint hierarchy, both cohorts have the same ranking of predictor levels for morpheme type, following context, stress, and, for the most part, preceding context. The one difference is preceding /s/, which highly favours deletion among younger speakers, but slightly disfavours deletion among older speakers. The one disadvantage of this *Goldvarb*-style table is that it does not show the individual, per-level significance measures. Looking at <span class="in">`td.glmer.not.young`</span> below shows that the probability of <span class="in">`Deletion`</span> among middle/older speakers' preceding /s/ tokens is not statistically different from the mean. In other words, predicting /s/ is a strong favouring predictor of <span class="in">`Deletion`</span> among young speakers, but an inconsequential predictor among middle/older speakers. When examining the <span class="in">`glmer()`</span> outputs below, preceding /s/ is <span class="in">`Before4`</span>. What the output of <span class="in">`td.glmer.not.young`</span> also shows is that preceding other fricatives are also not significantly different from the mean. This suggests that for middle/older speakers /s/ and other fricatives behaving similarly, while for younger speakers /s/ and other fricatives do not behave similarly. We will delve into this phenomenon in <span class="co">[</span><span class="ot">Part 4</span><span class="co">](116_lvcr.qmd)</span>. </span>
<span id="cb94-596"><a href="#cb94-596" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb94-597"><a href="#cb94-597" aria-hidden="true" tabindex="-1"></a><span class="co"># Subset data</span></span>
<span id="cb94-598"><a href="#cb94-598" aria-hidden="true" tabindex="-1"></a>td.young <span class="ot">&lt;-</span>td <span class="sc">%&gt;%</span> <span class="fu">subset</span>(Age.Group <span class="sc">==</span> <span class="st">"Young"</span>)</span>
<span id="cb94-599"><a href="#cb94-599" aria-hidden="true" tabindex="-1"></a>td.not.young <span class="ot">&lt;-</span> td <span class="sc">%&gt;%</span> <span class="fu">subset</span>(Age.Group <span class="sc">!=</span> <span class="st">"Young"</span>)</span>
<span id="cb94-600"><a href="#cb94-600" aria-hidden="true" tabindex="-1"></a><span class="co"># Create young speaker regression model</span></span>
<span id="cb94-601"><a href="#cb94-601" aria-hidden="true" tabindex="-1"></a>td.glmer.young <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td.young, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-602"><a href="#cb94-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-603"><a href="#cb94-603" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.young)</span>
<span id="cb94-604"><a href="#cb94-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-605"><a href="#cb94-605" aria-hidden="true" tabindex="-1"></a><span class="co"># Create middle/old speaker regression model</span></span>
<span id="cb94-606"><a href="#cb94-606" aria-hidden="true" tabindex="-1"></a>td.glmer.not.young <span class="ot">&lt;-</span> <span class="fu">glmer</span>(Dep.Var <span class="sc">~</span> After.New <span class="sc">+</span> Morph.Type <span class="sc">+</span> Before <span class="sc">+</span> Stress <span class="sc">+</span> Phoneme <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> Speaker), <span class="at">data =</span> td.not.young, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="fu">glmerControl</span>(<span class="at">optCtrl =</span> <span class="fu">list</span>(<span class="at">maxfun =</span> <span class="dv">20000</span>), <span class="at">optimizer =</span> <span class="st">"bobyqa"</span>))</span>
<span id="cb94-607"><a href="#cb94-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-608"><a href="#cb94-608" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(td.glmer.not.young)</span>
<span id="cb94-609"><a href="#cb94-609" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb94-610"><a href="#cb94-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-611"><a href="#cb94-611" aria-hidden="true" tabindex="-1"></a>Despite how useful a *Goldvarb*-style table is, it is not the only way to report the results you've produced. Nor is the estimate the only information you have. There are other interesting values in your `summary(td.glmer)` output. Going left to right, after the estimate there is the standard error, the $z$-value and the $p$-value. According to Gregory Guy in his [*LVC guidelines for reporting quantitative results*](http://gregoryrguy.com/wp-content/uploads/Guy-2018-Guidelines-for-reporting-quantitative-results-LVC-Nov-18-2018.pdf), reporting the estimates, standard errors, and significance is desirable. Whether reporting the $z$-scores is required is unclear. @fig-lme4table reports <span class="in">`td.glmer`</span> in a format more similar to the <span class="in">`lme4`</span> output. The likelihoods in @fig-lme4table are presented in log odds. They correspond exactly to the probabilities in @fig-gvtable1. One addition to the information in the <span class="in">`lme4`</span> output included in @fig-lme4table is the Observation columns. It is very important to report these distributions by factor/parameter level, preferably in your table, or somewhere else in your manuscript. </span>
<span id="cb94-612"><a href="#cb94-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-613"><a href="#cb94-613" aria-hidden="true" tabindex="-1"></a>You also may want to report in your table additional measures of model fit ($R^2$) and whether the model is an improvement over the null model. </span>
<span id="cb94-614"><a href="#cb94-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-615"><a href="#cb94-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-616"><a href="#cb94-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-617"><a href="#cb94-617" aria-hidden="true" tabindex="-1"></a><span class="al">![Mixed effects logistic regression analysis of the contribution of external and internal factors to the probability of /t, d/ -deletion in Cape Breton English for two age groups](images/lme4table.png)</span>{#fig-lme4table width="80%"}</span>
<span id="cb94-618"><a href="#cb94-618" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
  </div>
</footer>



<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>